[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I’ve worked as Software Engineer, Data Scientist and Data Engineering since 2002 I worked in different industries and programming languages.\nThis blog is a space for me to explain concepts as well as share my ideas and opnions.\nPlease comment !"
  },
  {
    "objectID": "posts/2012-11-12-separated-interface-design-pattern/index.html",
    "href": "posts/2012-11-12-separated-interface-design-pattern/index.html",
    "title": "Separated Interface Design Pattern",
    "section": "",
    "text": "When developing a system in many cases it is possible to identify dependencies among different layers whose responsibilities are well defined in the system.\nSome examples of layer dependencies are:\n\nController layer dependency and UI layer\nDomain logic layer and persistence layer\n\nOne strategy to remove dependencies between layers is to use the separated interface design pattern. This pattern consists of defining an interface from the bottom layer that is going to be used by the top layer. See diagram below to understand how it works for controller and UI layer:\n\nThe controllers in the example above only reference interface views and never know which view implementation they are actually working with.\nThis design pattern is recommended for a system when:\n\nOne layer (such as a controller) will be reused to be plugged into different versions of the other layer (such as HTML5 and native view layer implementations)\nLayers are easier to be tested in isolation\nIt is not desired that one layer has API dependencies from the other layer\n\nReferences:\n\nMartin Fowler, Patterns of Enterprise Application Architecture, Separated Interface, Pages 475-479\nSeparated Interface, http://martinfowler.com/eaaCatalog/separatedInterface.html\nDeveloping Software for Multi Mobile Devices, http://martinfowler.com/articles/multiMobile/"
  },
  {
    "objectID": "posts/2009-03-12-using-net-nullable-types-with-nhibernate-12/index.html",
    "href": "posts/2009-03-12-using-net-nullable-types-with-nhibernate-12/index.html",
    "title": "Using .NET Nullable Types with NHibernate 1.2",
    "section": "",
    "text": "Originally, NHibernate 1.2 does not support nullable types from .NET such as DateTime?, int?, bool?, etc. but that can be solved by implementing specific NHibernate specific user types.\nNot all nullable user types are listed for all .NET nullable types are listed below. But it can be easily done by following the example specially for numeric types.\nHowever if you need help you jut send an email.\nNullable user types code listings:\nNullableDateTimeType.cs\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing NHibernate.UserTypes;\nusing NHibernate;\nusing System.Data;\nusing NHibernate.SqlTypes;\n\nnamespace Utilitario.GerenciaDados\n{\n  public class NullableDateTimeType : IUserType\n  {\n      #region IUserType Members\n      public bool Equals(object x, object y)\n      {\n          return object.Equals(x, y);\n      }\n      public int GetHashCode(object x)\n      {\n          return x.GetHashCode();\n      }\n      public object NullSafeGet(IDataReader rs, string[] names, object owner)\n      {\n          //object valor = NHibernateUtil.DateTime.NullSafeGet(rs, names[0]);\n          object valor = null;\n          if (rs[names[0]] != DBNull.Value)\n              valor = Convert.ToDateTime(rs[names[0]]);\n\n          DateTime? dateTime = null;\n\n          if (valor != null)\n          {\n              dateTime = (DateTime)valor;\n          }\n          return dateTime;\n      }\n      public void NullSafeSet(IDbCommand cmd, object value, int index)\n      {\n          if (value == null)\n          {\n              NHibernateUtil.String.NullSafeSet(cmd, null, index);\n          }\n          else\n          {\n              DateTime? dateTime = (DateTime)value;\n              NHibernateUtil.AnsiString.NullSafeSet(cmd, dateTime.Value.ToString(\"yyyy/MM/dd HH:mm:ss.fff\"), index);\n          }\n      }\n      public object DeepCopy(object value)\n      {\n          return value;\n      }\n      public object Replace(object original, object target, object owner)\n      {\n          return original;\n      }\n      public object Assemble(object cached, object owner)\n      {\n          return cached;\n      }\n      public object Disassemble(object value)\n      {\n          return value;\n      }\n      public SqlType[] SqlTypes\n      {\n          get { return new SqlType[] { new StringSqlType() }; }\n      }\n      public Type ReturnedType\n      {\n          get { return typeof(string); }\n      }\n      public bool IsMutable\n      {\n          get { return false; }\n      }\n      #endregion\n  }\n}\nNullableBooleanType.cs\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing NHibernate.UserTypes;\nusing NHibernate;\nusing System.Data;\nusing NHibernate.SqlTypes;\n\nnamespace Utilitario.GerenciaDados\n{\n  public class NullableBooleanType : IUserType\n  {\n      #region IUserType Members\n      public bool Equals(object x, object y)\n      {\n          return object.Equals(x, y);\n      }\n      public int GetHashCode(object x)\n      {\n          return x.GetHashCode();\n      }\n      public object NullSafeGet(IDataReader rs, string[] names, object owner)\n      {\n          object valor = NHibernateUtil.Boolean.NullSafeGet(rs, names[0]);\n          bool? caracter = null;\n          if (valor != null)\n          {\n              caracter = (bool)valor;\n          }\n          return caracter;\n      }\n      public void NullSafeSet(IDbCommand cmd, object value, int index)\n      {\n          if (value == null)\n          {\n              NHibernateUtil.Boolean.NullSafeSet(cmd, null, index);\n          }\n          else\n          {\n              bool? caracter = (bool)value;\n              NHibernateUtil.Boolean.NullSafeSet(cmd, caracter.Value, index);\n          }\n      }\n      public object DeepCopy(object value)\n      {\n          return value;\n      }\n      public object Replace(object original, object target, object owner)\n      {\n          return original;\n      }\n      public object Assemble(object cached, object owner)\n      {\n          return cached;\n      }\n      public object Disassemble(object value)\n      {\n          return value;\n      }\n      public SqlType[] SqlTypes\n      {\n          get { return new SqlType[] { new StringSqlType() }; }\n      }\n      public Type ReturnedType\n      {\n          get { return typeof(string); }\n      }\n      public bool IsMutable\n      {\n          get { return false; }\n      }\n      #endregion\n  }\n}\nNullableCharType.cs\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing NHibernate.UserTypes;\nusing NHibernate;\nusing System.Data;\nusing NHibernate.SqlTypes;\n\nnamespace Utilitario.GerenciaDados\n{\n  public class NullableCharType : IUserType\n  {\n      #region IUserType Members\n      public bool Equals(object x, object y)\n      {\n          return object.Equals(x, y);\n      }\n      public int GetHashCode(object x)\n      {\n          return x.GetHashCode();\n      }\n      public object NullSafeGet(IDataReader rs, string[] names, object owner)\n      {\n          object valor = NHibernateUtil.Character.NullSafeGet(rs, names[0]);\n          Char? caracter = null;\n          if (valor != null)\n          {\n              caracter = (Char)valor;\n          }\n         return caracter;\n      }\n      public void NullSafeSet(IDbCommand cmd, object value, int index)\n      {  \n          if (value == null)\n          {\n               NHibernateUtil.Character.NullSafeSet(cmd, null, index);\n          }\n          else\n          {\n              Char? caracter = (Char)value;\n              NHibernateUtil.Character.NullSafeSet(cmd, caracter.Value, index);\n          }\n      }\n      public object DeepCopy(object value)\n      {\n          return value;\n      }\n      public object Replace(object original, object target, object owner)\n      {\n          return original;\n      }\n      public object Assemble(object cached, object owner)\n      {\n          return cached;\n      }\n      public object Disassemble(object value)\n      {\n          return value;\n      }\n      public SqlType[] SqlTypes\n      {\n          get { return new SqlType[] { new StringSqlType() }; }\n      }\n      public Type ReturnedType\n      {\n          get { return typeof(string); }\n      }\n      public bool IsMutable\n      {\n          get { return false; }\n      }\n      #endregion\n  }\n}\nNullableDecimalType.cs\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing NHibernate.UserTypes;\nusing System.Data;\nusing NHibernate.Util;\nusing NHibernate;\nusing NHibernate.SqlTypes;\n\nnamespace Utilitario.GerenciaDados\n{\n  public class NullableDecimalType : IUserType\n  {\n      #region IUserType Members\n      public bool Equals(object x, object y)\n      {\n          return object.Equals(x, y);\n      }\n      public int GetHashCode(object x)\n      {\n          return x.GetHashCode();\n      }\n      public object NullSafeGet(IDataReader rs, string[] names, object owner)\n      {\n          object valor = NHibernateUtil.Decimal.NullSafeGet(rs, names[0]);\n          Decimal? inteiro = null;\n          if (valor != null)\n          {\n              inteiro = (Decimal)valor;\n          }\n          return inteiro;\n      }\n      public void NullSafeSet(IDbCommand cmd, object value, int index)\n      {\n          if (value == null)\n          {\n              NHibernateUtil.Decimal.NullSafeSet(cmd, null, index);\n          }\n          else\n          {\n              Decimal? inteiro = (Decimal)value;\n              NHibernateUtil.Decimal.NullSafeSet(cmd, inteiro.Value.ToString().Replace(',','.'), index);\n          }\n      }\n      public object DeepCopy(object value)\n      {\n          return value;\n      }\n      public object Replace(object original, object target, object owner)\n      {\n          return original;\n      }\n      public object Assemble(object cached, object owner)\n      {\n          return cached;\n      }\n      public object Disassemble(object value)\n      {\n          return value;\n      }\n      public SqlType[] SqlTypes\n      {\n          get { return new SqlType[] { new StringSqlType() }; }\n      }\n      public Type ReturnedType\n      {\n          get { return typeof(string); }\n      }\n      public bool IsMutable\n      {\n          get { return false; }\n      }\n      #endregion\n  }\n}\nNullableDoubleType.cs\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing NHibernate.UserTypes;\nusing NHibernate;\nusing NHibernate.SqlTypes;\nusing System.Data;\n\nnamespace Utilitario.GerenciaDados\n{\n  public class NullableDoubleType : IUserType\n  {\n      #region IUserType Members\n      public bool Equals(object x, object y)\n      {\n          return object.Equals(x, y);\n      }\n      public int GetHashCode(object x)\n      {\n          return x.GetHashCode();\n      }\n      public object NullSafeGet(IDataReader rs, string[] names, object owner)\n      {\n          object valor = NHibernateUtil.Double.NullSafeGet(rs, names[0]);\n          Double? valorD = null;\n          if (valor != null)\n          {\n              valorD = (double)valor;\n          }\n          return valorD;\n      }\n      public void NullSafeSet(IDbCommand cmd, object value, int index)\n      {\n          if (value == null)\n          {\n              NHibernateUtil.Double.NullSafeSet(cmd, null, index);\n          }\n          else\n          {\n              Double? valor = (Double)value;\n              NHibernateUtil.Double.NullSafeSet(cmd, valor.Value.ToString().Replace(',','.'), index);\n          }\n      }\n      public object DeepCopy(object value)\n      {\n          return value;\n      }\n      public object Replace(object original, object target, object owner)\n      {\n          return original;\n      }\n      public object Assemble(object cached, object owner)\n      {\n          return cached;\n      }\n      public object Disassemble(object value)\n      {\n          return value;\n      }\n      public SqlType[] SqlTypes\n      {\n          get { return new SqlType[] { new StringSqlType() }; }\n      }\n      public Type ReturnedType\n      {\n          get { return typeof(string); }\n      }\n      public bool IsMutable\n      {\n          get { return false; }\n      }\n      #endregion\n  }\n}\nNullableInt32Type.cs\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Text;\nusing NHibernate.UserTypes;\nusing System.Data;\nusing NHibernate.Util;\nusing NHibernate;\nusing NHibernate.SqlTypes;\n\nnamespace Utilitario.GerenciaDados\n{\n  public class NullableInt32Type : IUserType\n  {\n      #region IUserType Members\n      public bool Equals(object x, object y)\n      {\n          return object.Equals(x, y);\n      }\n      public int GetHashCode(object x)\n      {\n          return x.GetHashCode();\n      }\n      public object NullSafeGet(IDataReader rs, string[] names, object owner)\n      {\n          object valor = NHibernateUtil.Int32.NullSafeGet(rs, names[0]);\n          Int32? inteiro = null;\n          if (valor != null)\n          {\n              inteiro = (Int32)valor;\n          }\n          return inteiro;\n      }\n      public void NullSafeSet(IDbCommand cmd, object value, int index)\n      {\n          if (value == null)\n          {\n              NHibernateUtil.Int32.NullSafeSet(cmd, null, index);\n          }\n          else\n          {\n              Int32? inteiro = (int)value;\n              NHibernateUtil.Int32.NullSafeSet(cmd, inteiro.Value, index);\n          }\n      }\n      public object DeepCopy(object value)\n      {\n          return value;\n      }\n      public object Replace(object original, object target, object owner)\n      {\n          return original;\n      }\n      public object Assemble(object cached, object owner)\n      {\n          return cached;\n      }\n      public object Disassemble(object value)\n      {\n          return value;\n      }\n      public SqlType[] SqlTypes\n      {\n          get { return new SqlType[] { new StringSqlType() }; }\n      }\n      public Type ReturnedType\n      {\n          get { return typeof(string); }\n      }\n      public bool IsMutable\n      {\n          get { return false; }\n      }\n      #endregion\n  }\n}"
  },
  {
    "objectID": "posts/2023-04-10-time-to-blog-again/index.html",
    "href": "posts/2023-04-10-time-to-blog-again/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "After a very long winter to share ideas and thought in the tech and research area, I decided to be back with a shiny and practical bloging tool.\nThis is my first blog page with github pages and quarto. Quarto is a publishing tool that allows to mix text in Markdown, diagrams and also python or r-generated graphics.\nHope yo be able to finally be able to share good content here."
  },
  {
    "objectID": "posts/2013-12-18-rails-new-framework---old-design-problems/index.html",
    "href": "posts/2013-12-18-rails-new-framework---old-design-problems/index.html",
    "title": "Rails: New Framework - Old Design Problems",
    "section": "",
    "text": "I have been programming for Rails for about 2-3 years now. As I came from a C# background it was a bit awkward for me to see some design principles I took as good practices being unashamedly broken such as:\n\ndata-driven models mixed with persistence logic instead of plain old domain objects\ncontrollers being used as application scenarios instead of coordinators between my actual application object and the view ( that was my understanding of MVC )\n\n\nAt that time I just thought it was the ruby-on-rails way of doing things and as a good newcomer in the ruby developer community I decided I should learn and listen more from other rails developers and forums than telling what the best practices should be.\n\n\n\n\n\nHowever after some years of work experience I realized some of those design problems were not sufficiently addressed for some anti-patterns: ( At least not until this year - some problems are still not addressed )\n\n\n\nfat controllers / skinny models\nskinny controllers / fat models\ngod models\ntransparent polyglot persistence in domain models ( SQL, NoSQL, Graph, etc … )\n\n\nNote that these design problems were solved in other programming environments long ago.\n\n\n\n\n\nNow with the maturity of rails developer community and the increasing adoption of rails in many enterprises I see design patterns and ideas being presented more often. \n\n\n\nThe objective of these ideas seems to be the same: keep active record models focused only on data and extracting out logic of any kind ( business, view, etc.. ) to other classes or modules.\n\n\nSome ideas that called my attention are:\n\n\n\nUse of service objects that orchestrate rails models in handling complex scenarios\nUse of rails concerns (modules) to extract behavior or methods that do not belong to the model responsibility (which in rails means data persistence and validation)\n\n\nSome oppose to rails concerns because it can lead your rails model class to have many roles instead of one-role. ( This is a popular clean code principle: one class, one role )\n\n\nHowever in his article DHH gave good reasons for doing it what actually made me open an exception for this clean code principle for this particular ruby case. ( I am a clean code fan and exceptions are rare)\n\n\n\n\n\nIn this case this clean code principle of one-role-class became a bit different for me after reading DHH article (see reference below in chubby models): \n\n\n\none class should have one IMPLEMENTATIONAL role. \n\n\n\nIn Ruby a rails model should implement only ONE role while it can be injected by many others.\n\n\nFor instance it is not a problem that your class contain many roles since they come from mixins.\n\n\nHowever mixins (or Rails concerns) should augment the rails model features and not make your class implementation dependent on them. It is not forbidden to be dependent on mixins such as by active record or mongoid since they are part of the one implementational role defined for the class but some caution is needed.\n\n\n\n\n\nIn the other hand the idea of using a service object can make it clear that some complex business concepts are executed separately. Scenarios include payment process, authentication and many others. Its benefit is very clear to me.\n\n\n\n\n\nBoth ideas are of great help to keep both controllers and models on a diet ( skinny controller / skinny models ) but other design problems such as transparent polyglot persistence and possible many others remain unanswered.\n\n\n\n\n\nI hope to see what the ruby community will have to say about that in the future.\n\n\nMaybe I can answer some of those questions, who knows ?\n\n\n\n\n\n\nReferences:\n\n\nhttp://blog.codeclimate.com/blog/2012/10/17/7-ways-to-decompose-fat-activerecord-models/\n\n\nhttp://37signals.com/svn/posts/3372-put-chubby-models-on-a-diet-with-concerns"
  },
  {
    "objectID": "posts/2008-07-24-scrum-as-a-criteria-for-venture-capital-groups/index.html",
    "href": "posts/2008-07-24-scrum-as-a-criteria-for-venture-capital-groups/index.html",
    "title": "Scrum as a criteria for Venture Capital Groups",
    "section": "",
    "text": "I just read a Foreword from Jeff Sutherland ( co-creator of Scrum ) from the book “Scrum and XP from the Trenches” where he comments how he chooses companies who really apply Scrum framework ( an agile framework or methodology to develop software ) for a venture capital group as an agile coach.\nThe more time pass the more I realize how agile software development will play an important role in near future. It already plays an important role but it can become a requirement for startup companies in search for funding from venture capital groups.\nIf a company can not deliver its products in time or can not deliver working software or can not deliver something that was not what the client was expecting, it should not be expected that they would receive funding. As Mike Cohn cited in the same book in his foreword, agile development is not about beautiful documentation or future-problem-proof code, it is about software done and working. And that’s exactly what clients need and expect from a software company.\nAt the same time, Scrum as well as other kinds of agile software ideas ( be it frameworks, methodologies or practices ) is very easy to put in practice. Any company or organization can start using this idea anytime they want.\nIf you have an idea about how is the Scrum process in five minutes or so, take a look at this articles: http://www.softhouse.se/Uploades/Scrum_eng_webb.pdf\nAddionally the book “Scrum and XP from the Trenches” mentioned in the beginning of this post can be downloaded here: http://www.infoq.com/minibooks/scrum-xp-from-the-trenches\nPersonally, as a software developer and a small investor I will take Jeff’s tip for future investments in tech companies."
  },
  {
    "objectID": "posts/2007-07-03-why-developers-do-not-like-to-model-the-real-world-/index.html",
    "href": "posts/2007-07-03-why-developers-do-not-like-to-model-the-real-world-/index.html",
    "title": "Why developers do not like to model the Real World ?",
    "section": "",
    "text": "Years ago the concept of roles, real world modeling, reusability and many others were not known. People with different roles were modeled in different entities ( tables or classes ) as if they were different things. In many database models such as the Northwind example we would find a table for Clients, another table for Vendors, a table for Employees and so on.\nThis kind of approach leads to data ambiguity since a Person can be an Employee in some occasions and a Vendor in other occasions or this Person can be a Client. So if a Persons must have his address, name, contact, etc. modified, this change must be reflected in several other tables. This business rule or better this developer rule should be remembered by anyone responsible for developing a system that could modify the data in one of these tables.\nThe approach changed but recently I was taking a look at a Class Diagram from a work colleague and it called my attention that he modeled the Accounting Role as Class Accountant.\nIt is not uncommon to see the same pattern when modeling peoples roles in many other Class Diagrams or even Data Diagram ( Entity Relation ) . Many developers usually create a class (or table) for each role like this:\n\nIt is not hard to see that as long as the system grows, more roles are needed. The additional classes multiply in the Class Model making it each time more complex to understand.\nInterestingly there is an Analysis Pattern that deals with people’s roles problem by providing a more elegant Class Modeling like this:\n\nNow the roles are better organized and if more roles are needed they can be added to the Class Hierarchy. And that is all right.\nThis could be a perfect solution to the problem but let me ask you a question.\nDo the roles really exist in Real World ?\nI mean, imagine there are no computers and information systems, how do you do to know someone’s role in your organization ? Do you ask: What’s your role ? Off course not.\nIf you are working for a Health Care Company, for example, in order to check if “Jack” is a doctor you ask him his Doctor License ( or Medical License or whatever document is used in your country ). To work as a Doctor, Jack must have this document (or license). He may not carry this document with him maybe it may not exist physically but there is some sort of license or document that grants him the permission to work with others people’s lives.\nThe same happens for accountants. Accountants do not work with people lives but in many countries they must have a document or license that enables him or her to do their jobs.\nIn order to know if someone is an accountant, you just have to check if he has an Accountant Registration ( or any name you prefer ).\nUsing document or license ( think of licenses and document as the same thing ) metaphor instead of roles gives you a more natural representation of your business rules. If the Class Diagram is more naturally represented by using Real World characteristics it is also more intuitive. Thus it can be better understood and learned by newcome developers or other developers in a large enterprise system. Check out the Class Diagram below:\n\nThe Class Diagram above shows a Person with his/her documents the way as it is in the Real World. If a another Document Type is needed it can be added to the hierarchy just like the prior class diagram."
  },
  {
    "objectID": "posts/2011-08-28-javascript-object-oriented-programming/index.html",
    "href": "posts/2011-08-28-javascript-object-oriented-programming/index.html",
    "title": "JavaScript: Object Oriented Programming",
    "section": "",
    "text": "By using functions and the structures above it is possible to a function object which syntax works just like a C++/Java class. See examples below."
  },
  {
    "objectID": "posts/2011-08-28-javascript-object-oriented-programming/index.html#classes",
    "href": "posts/2011-08-28-javascript-object-oriented-programming/index.html#classes",
    "title": "JavaScript: Object Oriented Programming",
    "section": "Classes",
    "text": "Classes\nIn JavaScript classes are declared as functions.\nfunction Task(name,dueDate)\n{\n    this.name = name;\n    this.dueDate = dueDate;\n};\nvar myTask = new Task(\"Clean house\",\"2011-07-01\");\nmyTask.name = \"some new name\";"
  },
  {
    "objectID": "posts/2011-08-28-javascript-object-oriented-programming/index.html#methods",
    "href": "posts/2011-08-28-javascript-object-oriented-programming/index.html#methods",
    "title": "JavaScript: Object Oriented Programming",
    "section": "Methods",
    "text": "Methods\nMethods are declared by extending the function prototype.\nvar User = function(email,password) {\n    this.email = \"\"; // public field\n    this.password = \"\";\n};\nUser.prototype.generatePassword = function() {  // public method\n    this.password = \"generatedpass\";\n}\nvar user = new User(\"you@email.com\",\"mypassword\");\nuser.generatePassword(); // password is generatedpass\nAlternatively methods can be declared inside the function declaration.\nvar User = function(email,password) {\n    this.email = \"\";\n    this.password = \"\";\n    this.generatePassword = function() { \n        this.password = \"generatedpass\";\n    };\n};"
  },
  {
    "objectID": "posts/2011-08-28-javascript-object-oriented-programming/index.html#inheritance",
    "href": "posts/2011-08-28-javascript-object-oriented-programming/index.html#inheritance",
    "title": "JavaScript: Object Oriented Programming",
    "section": "Inheritance",
    "text": "Inheritance\nIn order to make a class inherit from another class, the subclass prototype must be set to the desired parent object. It is also necessary to set the constructor as the current class which is a little od. See example below.\nfunction Person() {\n    this.firstname = \"James\";\n};\nPerson.prototype.generateName = function() {\n    this.firstname = \"generatedname\";\n};\n\nfunction Student() {\n    this.school = \"Rahway School\";\n};\nStudent.prototype = new Person();\nStudent.prototype.constructor = Student;\nStudent.prototype.setBestSchool = function() {\n    this.school = \"Best school in town\";\n};"
  },
  {
    "objectID": "posts/2011-08-28-javascript-object-oriented-programming/index.html#polymorphism",
    "href": "posts/2011-08-28-javascript-object-oriented-programming/index.html#polymorphism",
    "title": "JavaScript: Object Oriented Programming",
    "section": "Polymorphism",
    "text": "Polymorphism\nPolymorphism can be achieved by simply declaring methods with the same name. Consider the hierarchy of figures as an example below.\nfunction Photo() {    \n}\nPhoto.prototype.getDestinationPath = function() { \n    return \"./photos/common\";\n};\nfunction PartyPhoto() {\n}\nPartyPhoto.prototype = new Photo();\nPartyPhoto.prototype.constructor = PartyPhoto;\nPartyPhoto.prototype.getDestinationPath = function() {\n    return \"./photos/parties\";\n};\n\nphoto = new Photo();\nphoto.getDestinationPath(); // path for common photos\n\npartyPhoto = new PartyPhoto();\npartyPhoto.getDestinationPath(); // path for party photos"
  },
  {
    "objectID": "posts/2011-08-28-javascript-object-oriented-programming/index.html#encapsulation",
    "href": "posts/2011-08-28-javascript-object-oriented-programming/index.html#encapsulation",
    "title": "JavaScript: Object Oriented Programming",
    "section": "Encapsulation",
    "text": "Encapsulation\nIn the examples above all attributes and methods were public. In order to declare private attributes or methods one solution is to follow the template code below: (taken from http://www.codeproject.com/KB/scripting/jsoops.aspx )\nfunction MyClass(){    \n    //Private members\n    return{\n        //Public members\n    }}\nAn App class can be implemented as:\nfunction App(appname,description) {\n    var _name = appname;\n    var _description = description\n    return {\n        getName: function() { return _name; },\n        getDescription: function() { return _description; },\n        setName: function(appname) { _name = appname; },\n        setDescription: function(description) { _description = description; }\n    };    \n}\nvar myApp = new App(\"voila\",\"my game\");\nvar.setName(\"other game\");\nPlease note that this approach does not offer a way to have encapsulation and inheritance at the same time. Read next section to know one way to achieve this."
  },
  {
    "objectID": "posts/2011-08-28-javascript-object-oriented-programming/index.html#inheritance-with-encapsulation",
    "href": "posts/2011-08-28-javascript-object-oriented-programming/index.html#inheritance-with-encapsulation",
    "title": "JavaScript: Object Oriented Programming",
    "section": "Inheritance with Encapsulation",
    "text": "Inheritance with Encapsulation\nBy experimenting with the approach above, I found out a different way that made it possible to have both encapsulation and inheritance in JavaScript. The idea is to declare private members as function variables as above and then augment the parent object with the desired public functions. Thus it is not necessary to work with prototypes. Take the generic Person class as an example:\nfunction Person(name) {\n    // Private Members\n    var _name = \"\";\n    // Public Members (accesses private members)\n    var obj = new Object();\n    obj.setName = function(name) { _name = name; };\n    obj.getName = function() { return _name;  };  \n    // Constructor\n    obj.setName(name);\n    return obj;\n};\nA person instance will have access to getName and SetName but not _name attribute and therefore we have encapsulation. For a Student class that inherits from Person, the code would be:\nfunction Student(name,school) {\n    // Private Members\n    var _school = \"\";\n    // Creating parent object: Studen inherits from Person\n    var parent = new Person(name);\n    // Augmenting parent object with Student methods\n    parent.setSchool = function(school) { _school = school; };\n    parent.getSchool = function() { return _school; };\n    // Constructor Logic (Initialization)\n    parent.setSchool(school);\n    return parent;\n};\nThese functions can be used just like normal classes:\nvar person = new Person(\"James\");\nperson._name; // undefined\nperson.getName(); // James\n\nvar student = new Student(\"Jack\",\"Orange City School\");\nstudent._name;        // undefined\nstudent.getName();  // Jack\nstudent._school;       // undefined\nstudent.getSchool(); // Orange City School"
  },
  {
    "objectID": "posts/2007-12-20-best-practice-to-handle-exceptions/index.html",
    "href": "posts/2007-12-20-best-practice-to-handle-exceptions/index.html",
    "title": "Best Practice to Handle Exceptions",
    "section": "",
    "text": "Modern programming languages come with try/catch/finally blocks and many times an Exception Hierarchy of classes is provided also.\nExceptions are a powerful tool that can be used to handle both system and user errors.\nWhen exceptions are thrown in some part of the code, the system keeps popping ( removing the head ) of the stack until it finds a catch statement that can handle that exception type.\nOne common way to capture exceptions is to write several catches from the most specific to the most generic exception class until you can capture the exception type appropriately according to its type.\nCheck code below:\ntry\n{\n  // code block\n}\ncatch ( SpecialSystemException e)\n{\n  // code to handle SpecialSystemException  \n}\ncatch ( SystemException e)\n{\n  // code to handle SystemException\n}\ncatch ( Exception e)\n{\n  // code to handle Exception\n}\nfinally\n{\n  // finishes code block\n}\nHowever in many cases it is desired to treat each exception same way according to its type in the entire system. In this case the code template shown above has some disadvantages:\n\nProgrammers must write more code to implement try/catch/finally code blocks to due the several “catch” statements for each exception type that is intended to treat\nCode to treat exception classes are replicated in the software code\n\nAnd finally if it demands more work and it is repeated than it is error prone\n\nIn order to solve this problem a better approach is to create a separate centralized class to treat all exceptions thrown from the system internally. Like the .NET pseudo-code example below:\npublic class ExceptionHandler\n{\n  public static void Handler(Exception exception)\n  {\n    if (exception.GetType() == typeof(SpecialSystemException))\n    {\n      // Code that deals with SpecialSystemException \n    }   \n    else if (exception.GetType() == typeof(SystemException))\n    { \n      // Code that deals with SystemException\n    }\n  else if (exeception.GetType() == typeof(Exception))\n  {\n      // Code that deals with Exception\n    }\n}\nReplacing the code of the first example:\ntry\n{\n  // code block\n}\ncatch ( Exception e)\n{\n  // Exceptions are now treated internally by the method below\n  ExceptionHandler.Handler(exception);\n}"
  },
  {
    "objectID": "posts/2009-08-27-dynamicproxy-an-elegant-solution-for-session-transaction-exception-management-in-nhibernate-or-any-other-orm/index.html",
    "href": "posts/2009-08-27-dynamicproxy-an-elegant-solution-for-session-transaction-exception-management-in-nhibernate-or-any-other-orm/index.html",
    "title": "DynamicProxy: An Elegant Solution for Session/Transaction/Exception Management in NHibernate (or any other ORM)",
    "section": "",
    "text": "Session management is a well solved problem for web applications and many detailed solutions can be found in the internet. The same is not true for winforms applications. Although there are solutions available in the internet, many of them are theoretical or just “complicated” for the medium programmer. Besides that it was difficult to find a solution (I have never found one) that could work for both web and winforms applications.\nAfter a while (days), it came up to me the idea of using service proxies with Castle Dynamic Proxies. It turned out to be the easiest and cleanest approach I could think of because it has the ability to inject (aspects) behaviour around the service methods.\nThe idea can be coded in the following way:\n\nService classes with standard namespace and virtual methods\n\nnamespace Sample.Service\n{\n  public class SystemLogRegistrationService\n  {\n    public virtual void Modify(long codLogSistema)\n    {\n      SystemLog systemLog = Repository.Get().Load(codLogSistema);            \n      systemLog.SetMachine = \"MAQUINA\" + DateTime.Now;\n      systemLog.SetUserName = \"PESSOA\" + DateTime.Now;            \n      systemLog.SetSystemName = \"SISTEMA\" + DateTime.Now;\n      Repository.Get().Save(systemLog);            \n    }\n  }\n}\nDo not get distracted with the service code. The important thing to notice above is that the service does not contain anything else other than processing the domain classes (in this case, SystemLog). Also note that all service methods must be virtual. Without that, dynamic proxy won’t work for these methods. The details of Repository implementation are out of the scope of this article and this subject is covered in enough details in several articles throughout the internet. (You can also send me a comment or email if you need information about that)\n\nUsage Example\n\nIn order to make use of proxified services, one must create some kind of generator whose creation will be explained next. The ProxyGenerator below is a simple static class for didactic purposes that is responsible for dynamically generate proxies from a given type injecting the necessary aspects such as session/transaction management and exception handling or any other aspect you might think about.\nSomeService serv = ProxyGenerator.InjectSessionTransactionExceptionAspects&lt;SomeService&gt;();\nserv.Modify(12048); // &lt;= Modify method has session/transaction/exception management\n\nCreating a proxy service factory\n\nThe proxy generator can be implemented using Castle Dynamic Proxy API.\nusing System;\nusing Castle.DynamicProxy;\n\nnamespace Sample.Persistence\n{\n  public static class ProxyGenerator \n  {\n    private static ProxyGenerator _generator = new ProxyGenerator();        \n    public static TService InjectSessionTransactionExceptionAspects&lt;TService&gt;()\n    {\n      return (TService)_generator.CreateClassProxy(\n        typeof(TService),\n        new SessionTransactionExceptionAspect());    \n    }\n  }\n}\n\nAn interceptor for the service class methods\n\nusing System;\nusing Castle.DynamicProxy;\nusing NHibernate;\nusing NHibernate.Context;\n\nnamespace Sample.Persistence\n{\n  /// \n  /// Intercepts service methods (must be virtual) and inject\n  /// session / transaction and exception aspects\n  /// \n  public class SessionTransactionExceptionAspect: IInterceptor\n  {\n    /// \n    /// Intercepts service methods and adds the following behaviors\n    /// &gt;&gt;&gt; Before executing a method:\n    ///     * opens session\n    ///     * begins transaction\n    /// &gt;&gt;&gt; After executing method:\n    ///     * Commits transaction\n    /// &gt;&gt;&gt; In case there is exception\n    ///     * Rollbacks transaction\n    ///     * Handles exception\n    /// &gt;&gt;&gt; At the end\n    ///     * Closes session\n    /// \n    public object Intercept(IInvocation invocation, params object[] args)\n    {\n      object retorno = null;\n      ITransaction tx = null;\n      try\n      {          \n        CurrentSessionContext.Bind(SessionFactory.Instance.OpenSession());\n        tx = SessionFactory.Instance.GetCurrentSession().BeginTransaction();\n        retorno = invocation.Proceed(args);\n        tx.Commit();\n      }\n      catch (Exception exception)\n      {\n        if (tx != null) { tx.Rollback(); }\n          throw exception;\n      }\n      finally\n      {\n        ISession s = SessionFactory.Instance.GetCurrentSession();\n        s.Close();\n        CurrentSessionContext.Unbind(s.SessionFactory);\n      }\n      return retorno;\n    }\n  }\n}\nAbove is the center of the whole idea. The interceptor class above captures only the service methods and ignores the rest. The following tasks are executed inside a try-catch-finally: (when it is a service method)\n\nSession is created\nTransaction is initialized\nThe method itself is executed\nif method is ok, transaction is confirmed\nif there is exception, transaction is cancelled and exception is handled\nFinally session is closed"
  },
  {
    "objectID": "posts/2023-05-07-naive-bayes-classifier/index.html",
    "href": "posts/2023-05-07-naive-bayes-classifier/index.html",
    "title": "Text Classification with Naive Baye’s",
    "section": "",
    "text": "In the context of NLP (natural language processing), Baye’s rule is given by: \\(P(category | word) = P(word | category) * P(category) / P(word)\\)\nwhere:\n\n\\(P(category | word)\\): probability of a category given a word\n\\(P(word | category)\\): probability of word given category\n\\(P(category)\\): probability of a category to occur\n\\(P(word)\\): probability of a word to occur\n\nFor a sequence of words, the formula becomes:\n\\(P(category | word_0, word_1, ..., word_n) = P(category) * \\frac{P(word_0 | category) * P(word_1 | category) * ... * P(word_n | category)}{P(word_0) * P(word_1) * ... * P(word_n)}\\)"
  },
  {
    "objectID": "posts/2023-05-07-naive-bayes-classifier/index.html#introduction",
    "href": "posts/2023-05-07-naive-bayes-classifier/index.html#introduction",
    "title": "Text Classification with Naive Baye’s",
    "section": "",
    "text": "In the context of NLP (natural language processing), Baye’s rule is given by: \\(P(category | word) = P(word | category) * P(category) / P(word)\\)\nwhere:\n\n\\(P(category | word)\\): probability of a category given a word\n\\(P(word | category)\\): probability of word given category\n\\(P(category)\\): probability of a category to occur\n\\(P(word)\\): probability of a word to occur\n\nFor a sequence of words, the formula becomes:\n\\(P(category | word_0, word_1, ..., word_n) = P(category) * \\frac{P(word_0 | category) * P(word_1 | category) * ... * P(word_n | category)}{P(word_0) * P(word_1) * ... * P(word_n)}\\)"
  },
  {
    "objectID": "posts/2023-05-07-naive-bayes-classifier/index.html#basic-idea",
    "href": "posts/2023-05-07-naive-bayes-classifier/index.html#basic-idea",
    "title": "Text Classification with Naive Baye’s",
    "section": "Basic Idea",
    "text": "Basic Idea\nNaive Baye’s programming is composed by the following steps: 1. count word frequency by category\nFor example, when classifying statements between categories: Positive and Negative:\nGiven the statements:\n\npositive: The happy fox\nnegative: The dead fox\npositive: Fox is happy\nnegative: Fox is dead\n\n\ncount word frequencies per category\n\nword table:\n\n\n\nword\npositive\nnegative\n\n\n\n\nthe\n1\n1\n\n\nfox\n2\n2\n\n\nhappy\n2\n0\n\n\ndead\n0\n2\n\n\nis\n1\n1\n\n\nTOTAL\n6\n6\n\n\n\n\ncompute table of probabilities\n\n\n\n\nword\npos_probability\nneg_probability\n\n\n\n\nthe\n1/6 = 0.1666\n1/6 = 0.1666\n\n\nfox\n2/6 = 0.3333\n2/6 = 0.3333\n\n\nhappy\n2/6 = 0.3333\n0/6 = 0\n\n\ndead\n0/6 = 0\n2/6 = 0.3333\n\n\nis\n1/6 = 0.1666\n1/6 = 0.1666\n\n\n\n\ncompute likelihood of a statement\n\nquery statement example: Is fox happy ?\n\\[\n\\prod_{i=1}^{m} \\frac{P(w_i|positive)}{P(w_i|negative)}=\n\\frac{P(is|positive)*P(fox|positive)*P(happy|positive)}{P(is|negative)*P(fox|negative)*P(happy|negative)}=\n\\frac{0.1666*0.3333*0.3333}{0.1666*0.3333*0}=\n\\]\nreplacing 0 in the formula above for a very small number as a temporary solution before we can later learn about Laplacian Smoothing:\n\\[\n\\frac{0.1666*0.3333*0.3333}{0.1666*0.3333*0.0001}=10000\n\\]\n10000 &gt; 1 therefore the statement is classified as positive"
  },
  {
    "objectID": "posts/2023-05-07-naive-bayes-classifier/index.html#laplacian-smoothing",
    "href": "posts/2023-05-07-naive-bayes-classifier/index.html#laplacian-smoothing",
    "title": "Text Classification with Naive Baye’s",
    "section": "Laplacian Smoothing",
    "text": "Laplacian Smoothing\nAvoids the problem of handling words with 0 frequency in one of the classes in the step 2 above when calculating word class probability. Note the words happy and dead in the example above.\n\\[\nP(w_i|class)=\\frac{freq(w_i, class)+1}{N_{class}+V}\n\\]\nwhere:\n\n\\(w_i\\): \\(i^{th}\\) word from the training data\n\\(class\\): the category class\n\\(N_{class}\\): number of categories\n\\(V\\): number of unique words in vocabulary"
  },
  {
    "objectID": "posts/2023-05-07-naive-bayes-classifier/index.html#log-likelihood",
    "href": "posts/2023-05-07-naive-bayes-classifier/index.html#log-likelihood",
    "title": "Text Classification with Naive Baye’s",
    "section": "Log Likelihood",
    "text": "Log Likelihood\nAvoids the problem of underflow (too small number) as a result of long multiplication of probabilities:\n\\[\nlog( a * b * c ) = log(a) + log(b) + log(c)\n\\]\nOriginal Solution\n\\[\n\\prod_{i=1}^{m} \\frac{P(w_i|positive)}{P(w_i|negative)}=\n\\frac{P(is|positive)*P(fox|positive)*P(happy|positive)}{P(is|negative)*P(fox|negative)*P(happy|negative)}=\n\\frac{0.1666*0.3333*0.3333}{0.1666*0.3333*0}\n\\]\nLog Solution with Non-Zero Correction\n\\(log( \\prod_{i=1}^{m} \\frac{P(w_i|positive) + 1}{P(w_i|negative) + 1} )=\\sum_{i=1}^{m} log(\\frac{P(w_i|positive) + 1}{P(w_i|negative) + 1})=\\)\n\\(log(\\frac{P(is|positive) + 1}{P(is|negative) + 1}) + log(\\frac{P(fox|positive) + 1}{P(fox|negative) + 1}) + log(\\frac{P(happy|positive) + 1}{P(happy|negative) + 1})=\\)\n\\(log(\\frac{0.1666 + 1}{0.1666 + 1}) + log(\\frac{0.3333 + 1}{0.3333 + 1}) + log(\\frac{0.3333 + 1}{0 + 1})=log(1) + log(1) + log(1.3333)=0 + 0 + 0.124 = 0.124 &gt; 0\\)\n(can be classified as positive)"
  },
  {
    "objectID": "posts/2023-05-07-naive-bayes-classifier/index.html#improved-naive-bayes-laplacian-smoothing-log-likelihood",
    "href": "posts/2023-05-07-naive-bayes-classifier/index.html#improved-naive-bayes-laplacian-smoothing-log-likelihood",
    "title": "Text Classification with Naive Baye’s",
    "section": "Improved Naive Baye’s Laplacian Smoothing + Log Likelihood",
    "text": "Improved Naive Baye’s Laplacian Smoothing + Log Likelihood\nAs a conclusion, a better naive bayes classifier can be built by using:\n\nlaplacian smoothing to avoid 0 probabilities\nlog likelihood to handle longer word sequences.\n\nTherefore the final classifier formula becomes:\n\\[\n\\sum_{i=1}^{m} log(\\frac{ \\frac{P(w_i|positive) + 1}{N_{class} + V} }{    \\frac{P(w_i|negative) + 1}{N_{class} + V}    })=\n\\]\nwhere m is each word in a sentence"
  },
  {
    "objectID": "posts/2008-03-19-rich-domain-objects/index.html",
    "href": "posts/2008-03-19-rich-domain-objects/index.html",
    "title": "Rich Domain Objects",
    "section": "",
    "text": "In object oriented programming, domain objects are the key of the software development. However, many programmers tend to write these classes as simple get/set storage just like the example below in pseudo-code:\nclass Client\n{\n    private long id;\n    public string Id\n    {\n        get { return this.id; }\n        set { this.id = value }\n    }\n    private string name;\n    public string Name\n    {\n        get {return this.name; }\n        set { this.name = value; }\n    }\n\n    private int registrationYear;\n    public int RegistrationYear\n    {\n        get { return this.registrationyear; }\n        set { registrationYear = value; }\n    }\n}\nThe instances of the class above are the so-called anemic-objects. These objects don’t verify their internal state and their behavior and thus accept any value as input.\nAs a consequence the extra-work is delegated to the application.\nHowever these objects are not very practical for complex domain models and they don’t take full power of the object programming. Classes not only carry data but also a functional part which are exactly the methods and properties.\nTo attack complex domains there are rich domain objects which are objects capable of verifying all these aspects internally preventing the programmers from having to remember them later at the time of building the application.\nRich domain objects help other developers not familiar with the business rules on how to create an application for that particular domain.\nIn order to work efficiently with rich domain objects the following design rules can be adopted:\n\nConstructors should contain required parameters to create a new instance for the class from the business point of view\n\n// Rule 1 - Constructor with mandatory parameters\npublic Client(name,registrationDate) {...}\n\nAlways use properties instead of accessing fields directly to read or modify data in the class implementation except obviously in the properties implementations\n\n// Rule 2 - Use properties instead of fields\n{ this.Name = name; this.RegistrationDate = registrationDate; }\n\nSet parameters should check the input parameters appropriately and check the objects internal state before altering the object according to the domain rules\n\npublic string Name\n{\n    get { return this.name; }\n    // Rule 3 - Set property checks the input value\n    set { \n        if (value == \"\") throw new SystemException(\"Empty name is invalid\");\n        this.name = value;\n    }\n}\n\nGet parameters should check the object internal state before returning a value\n\npublic int RegistrationYear\n{\n    //Rule 4-Get property checks object and application state before returning a value\n    get\n    {\n        if (User.CurrentUser().IsManager()) return this.registrationYear;\n        else throw new SystemException(\"No permission for Client's Registration Year.\");\n    }\n    set\n    {\n        if ((value &lt;&gt; DateTime.now.year)) throw new SystemException(\"Year must be from 1980 until now\");\n        this.registrationYear = value;\n    }\n}\n\nClasses should be designed in order to follow primarily the business model and then the data model\n\nFollowing this rules a Client class could be:\n// Rule 5 - Client Class is designed according to the business model\nclass Client\n{\n// Rule 1 - Constructor with mandatory parameters\npublic Client(name,registrationDate)\n    // Rule 2 - Use properties instead of fields\n    { this.Name = name; this.RegistrationDate = registrationDate; }\n\n    private string id;\n    public string Id\n    {\n        get { return this.id; }\n        set { this.id = value; }\n    }\n\n    private string name;\n    public string Name\n    {\n        get {return this.name; }\n        // Rule 3 - Set property checks the input value\n        set\n        {\n            if (value == \"\") throw new SystemException(\"Empty name is invalid\");\n            this.name = value;\n        }\n    }\n\n    private int registrationYear;\n    public int RegistrationYear\n    // Rule 4-Get property checks object and application state before returning a value\n    {\n        get\n        {\n            if (User.CurrentUser().IsManager()) return this.registrationYear;\n            else throw new SystemException(\"No permission for Client's Registration Year.\");\n        }\n        set\n        {\n            if ((value != DateTime.now.year)) throw new SystemException(\"Year must be from 1980 until now\");\n            this.registrationYear = value;\n        }\n    }\n}"
  },
  {
    "objectID": "posts/2008-08-19-efficient-software-development-process-with-open-source-tools-for-net/index.html",
    "href": "posts/2008-08-19-efficient-software-development-process-with-open-source-tools-for-net/index.html",
    "title": "Efficient Software Development Process with Open-Source Tools for .NET",
    "section": "",
    "text": "When a software is been built, a series of characteristics must be pursuit in order to deliver a quality product during the development process:\n\nAgility\n\nTestability\nReadability\nExtensibility\n\nAutomated Documentation\n\nIt it important to say that I presume many readers of this text are already convinced about the advantages brought by object oriented programming when compared to traditional development and the tools presented below support this kind of programming paradigm besides the goals specified above.\nObject-Relational Mapping Tool: Castle Project Active Record\nOne of the most time-consuming things in software development is mapping classes in tables.\nThis process is partially automated by tools such as NHibernate but the Active Record offered by Castle Project not only maps classes to tables but it is also capable to generate the database from the object model which confers agility to the software process.\nhttp://www.castleproject.org/activerecord/index.html\nSource-Code Standards: FXCop\nAlthough it is free, FXCop is not a free-software since its code is private owned by Microsoft.\nAnyway it is very a useful tool whose objective is to verify if quality metrics and/or naming conventions of a project are been followed appropriately by the team members.\nBy using naming well defined and known programming conventions, code readability is enhanced and different projects can be understood by every programmer in a software company.\nhttp://msdn.microsoft.com/en-us/library/bb429476(VS.80).aspx\nUnit Tests: NUnit\nIt is the most used automated testing tool for .NET . These tests play an important role in a software project since they bring more confidence to developers to change software when needed since they can point out when a certain piece of the software might be broken due to some modification. Obviously NUnit brings testability to the software development environment.\nhttp://www.nunit.org/index.php\nTest Coverage: PartCover\nHow can you know what parts of your code is being covered by automated tests ?\nThis process is called test coverage and it is the objective of PartCover.\nAltough NCover is largely mentioned in the net, PartCover is becoming increasingly\nimportant as a test coverage open-source project.\nhttp://sourceforge.net/projects/partcover/\nAutomated Documentation: NDoc\nDocumentation can be a time consuming task but without it, the software extensibility and maintainability can slow down considerably specially for people outside the project and unaware of coding practices. One of the fastest ways to get documentation is generating it from the source-code. NDoc can generate developer level documentation from the XML tags in the C# source-code.\nhttp://ndoc.sourceforge.net\nWeb Framework: MonoRail\nThe Castle Project seems to understand what is to have an agile development. Having this in mind, MonoRail is a web framework that truly obeys the MVC Design Pattern without slowing developers down. Besides agile, this framework lets us to have an improved readability also compared to traditional ASP.NET programming.\nhttp://www.castleproject.org/monorail/gettingstarted/index.html\nContinuous Integration: Cruise Control .NET\nPrior sections some tools for software quality were presented such as FXCop, NUnit, PartCover and NDoc. Although useful it is very easy for one of the team members to forget to manually execute some of this tools during the development process. Remembering and executing these tools can also be error prone since some member of the team can forget to execute some of these tools.\nIn order to overcome these drawbacks and others, continuous integration rised as one the most known practices from Extreme Programming (XP). ( See XP in http://www.extremeprogramming.org/ )\nBasically continuous integration is performed by a build tool such as Cruise Control ( http://cruisecontrol.sourceforge.net/ ) that is responsible for executing specified tasks necessary prior to software delivery to the users such as compilation checking, unit tests executing, quality metrics verification and finally publication. However another combination of tasks can be though such as email notification and many others.\nGenerally the continuous integration process is executed manually or during the night when there is low activity but it is possible to trigger this process through a version control system such as SVN prior to accept a commit requested by a team programmer."
  },
  {
    "objectID": "posts/2007-08-30-packages-a-tool-to-organize-classes/index.html",
    "href": "posts/2007-08-30-packages-a-tool-to-organize-classes/index.html",
    "title": "Packages: A Tool to Organize Classes",
    "section": "",
    "text": "One of these days I was taking to a work colleague about what should be the package (a.k.a. Namespace) of a certain class. Not rare there is a small debate about it. Should the class WorkerRiskActivity belong to the Health package or to the Activity package ? And so on ….\nAlthough it may sound a useless discussion it has been proven ( at least to our organization ) that this kind of worry is healthy specially in the long term.\nI can enumerate the following advantages in using good packages for classes:\n\nIt breaks the complexity of hundreds of classes in blocs composed by few classes just like folders for files.\n\n\n\nIt gives a clue for developer about what is the role of this class in the system.\n\n\nThe fully qualified name Finance.Sevices.DebtManagement tell you what the class actually does.\n\nIt organizes the logic architecture of your software. This is specially useful for layered architecture where the classes are organized according to the class role.\n\n\nOrganizing classes can also be confusing. In order to avoid wrong classification, the following anti-patterns are listed below:\n\nPackages with vagues names\n\nOne of the traps that should be avoided is to create packages with too vague names such as General, Etc or Miscellaneous. This names are going to be used by lazy developers to place classes they don’t want to think about how to classify to the right package.\n\nToo much debate about packages\n\nIn the other hand, organizing classes in packages should not give rise to a long debate. If a class was placed in the wrong package, a code refactoring can solve the problem later.\n\nPackage-by-layer\n\nAlthough it can sound perfectly reasonable to have classes organized by layer. Actually this kind of packages can be harmful since it is no more possible determine what kind of permission a specific package can have since this package actually has all kinds of classes from varying parts of your system that don’t relate to each other. The preferred way to use packages is to organize them by feature as it can be seen in all examples listed in this post. In fact this is not a “personal way” of modeling packages, this is the original purpose of a package.\nThus the package Finance has all classes that compounds a financial application including its UI layer, services and the problem domain classes."
  },
  {
    "objectID": "posts/2006-10-28-oo-paradigm-popularity/index.html",
    "href": "posts/2006-10-28-oo-paradigm-popularity/index.html",
    "title": "OO Paradigm Popularity",
    "section": "",
    "text": "As far as I know OO has existed since the 70’s. For a long time, OO was mainly used for academic projects. In the meantime relational databases gained popularity between comercial computer systems and so the relational model.\nThe relational model has also evolved gained popularity since it presented a concrete solution to the problem of how to store data of a business model.\nWith the rise of Java Programming Language, OO became much popular since it motivates the programmer to use this paradigm.\nOne of the most important characteristics of the OO paradigm for enterprise applications is that the data and the functional aspects of a business model could be abstracted. Thus OO paradigm offers a higher level of abstraction compared to the relational model however that didnn’t turn itself into a practical advantage for comercial system.\nRelational Databases are responsible for almost all data storage in computer systems while OO Databases ( not talking about Object-Relational Databases like Oracle ) are not sufficiently mature yet and although it was easier to build more complex software an old problem still persisted which is the OO paradigm and the relational model mistmatch problem deeply explored by Scott W Ambler.\n( http://www.agiledata.org/essays/impedanceMismatch.html )\nThis impedance mismatch use to consume a lot of time from OO programmers. For example, a line in a Person table in a relational model is represented as a Person object. Before in order to do that OO programmers had to program a persistence layer by hand. Besides time consuming it was also a complex task. These reasons were enough to put OO away from the comercial software market for several years.\nThe Object-Relational-Mapping Tools (ORM Tools ) addressed this issue more productive way. With these tools the columns of a table in the relational model were mapped to an attribute in a class in the OO model. These mappings can be done in a XML file, in a separate class or by using annotations. The most stable and well-documented so far is Hibernate.\n( www.hibernate.org )\nWhatever these mappings are described these tools made it possible to use OO in Enterprise Applications Projects. It was not necessary to spend so long time to implement object persistence and it was also possible to use OO in legacy relational databases.\nThere are even tools that generate the class code in Java or .NET and the mapping code from the database schema like MyGeneration.\n( http://www.mygenerationsoftware.com/portal/default.aspx )\nInterestingly there lot of articles out there saying that there is no evidence proving that the OO approach is a an advantage over the relational programming and not a long time ago some authors used to say that OO in Enterprise Applications was something impossible.\nIn my opnion OO offers advantage in a long term since the business model is gradually represented with a higher level of abstraction."
  },
  {
    "objectID": "posts/2012-12-06-rorm---ruby-domain-objects-with-persistence/index.html",
    "href": "posts/2012-12-06-rorm---ruby-domain-objects-with-persistence/index.html",
    "title": "RORM - Ruby Domain Objects with Persistence",
    "section": "",
    "text": "After some time using ActiveRecord and MongoId, I decided it was time to create a ruby ORM for domain objects as my first github project.\nhttps://github.com/hcmarchezi/rorm/blob/master/README.md"
  },
  {
    "objectID": "posts/2009-09-27-extreme-programming-impressions/index.html",
    "href": "posts/2009-09-27-extreme-programming-impressions/index.html",
    "title": "Extreme Programming Impressions",
    "section": "",
    "text": "Whe I first read about XP Programming in 2002 ( http://www.extremeprogramming.org/ ) which is one of the agile methodologies for software development I didn’t take it seriously.\nAt that time the authors of this methodology were saying that software didn´t need to be documented, models were not necessary or useful at all, people should be the documentation of the software, etc.\nImmediately it came to my mind that it couldn´t work for many small (and big) software companies due to several problems:\n– Software companies are constantly loosing and hiring workforce so how can they work if they keep loosing “documentation” which is on people´s minds ?\n– How can they know the “what”, “where” and “how” in the source code ?\nSome years have passed and this methodology has matured and besides that other good methodologies of the same family like Scrum have come up too.\nIt called my attention that many state-of-art tech companies like Google and Yahoo! were working with Scrum and I started to get curious to know what it is about.\nFive years later I decided to attend to a presentation about XP Programming in order to get a broader picture about it. It helped me to remove some miths I had such as the lack of documentation. Actually the Agile Methodology do not remove the activity of producing documentation but it just gave a different meaning for the documentation. The documentation should be provided if relevant for developers. It doesn´t have to include fancy diagrams but only the necessary information such as what is the system about, how to compile source-code, or other information that it is not self-explained in the system.\nAfter reading “The Toyota Way” I noticed that agile methodologies was greatly inspired by this administration model. This model is basically driven to reduce waste, in other words, we should do only the necessary to accomplish our objectives, no more or no less. By reducing waste we are also reducing unnecessary work what can mean different things depending on our project such as no documentation, few documentation, no models, etc.\nTherefore to be lean (and consequently agile), one must think on what tasks are been carried out and what tasks in the process should be eliminated if they have no value. Read the book above to have a good idea of the process."
  },
  {
    "objectID": "posts/2023-07-28-logistic-regression-for-text-classification/index.html",
    "href": "posts/2023-07-28-logistic-regression-for-text-classification/index.html",
    "title": "Text Classification with Logistic Regression",
    "section": "",
    "text": "Logistics regression is a well known statistics tool for classification including text. The steps to implement a text classifier with this statistic tool will be explained here."
  },
  {
    "objectID": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#introduction",
    "href": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#introduction",
    "title": "Text Classification with Logistic Regression",
    "section": "",
    "text": "Logistics regression is a well known statistics tool for classification including text. The steps to implement a text classifier with this statistic tool will be explained here."
  },
  {
    "objectID": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#training-flow",
    "href": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#training-flow",
    "title": "Text Classification with Logistic Regression",
    "section": "Training Flow",
    "text": "Training Flow\n\n\n\n\n\nflowchart LR\n    A[Text] --&gt; B[\"Feature_Extraction(T)\"]\n    B --&gt; C[\"Prediction_Function(X)\"]\n    C --&gt; D[\"Output Y^\"]\n    D --&gt; E[\"Cost_Function(Y, Y^)\"]\n    E --&gt; C"
  },
  {
    "objectID": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#vocabulary-feature-extraction",
    "href": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#vocabulary-feature-extraction",
    "title": "Text Classification with Logistic Regression",
    "section": "Vocabulary & Feature Extraction",
    "text": "Vocabulary & Feature Extraction\n\nOne-Hot-Encoding\nConsists of creating a vector of 0s and 1s (no other values) where each position represents a word in the vocabulary. If a word is present in a phrase (such a Twit) the corresponding position would be marked as 1 otherwise 0.\n\nProblem: Long training and prediction time: It can get too big and sparse when a large vocabulary from many different texts are used.\n\n\n\nNegative and Positive Frequencies\nThe idea is to use feature vectors to count word frequencies for each prediction category (such as positive/negative in sentiment analysis). Global feature vector is calculated for each word, following the steps below:\nMap(word) —&gt; occurrence of that word in a given class\n\n\n\n\nI\nam\nhappy\nsad\nnever\n\n\n\n\nPositive\n2\n2\n1\n0\n0\n\n\nNegative\n3\n3\n0\n2\n1"
  },
  {
    "objectID": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#preprocessing",
    "href": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#preprocessing",
    "title": "Text Classification with Logistic Regression",
    "section": "Preprocessing",
    "text": "Preprocessing\n\ntokenization - break text into array of words\nfrom nltk.tokenize import TweetTokenizer\nstop words - eliminate meaningless words (punctuation, articles, prepositions, not-important symbols, etc.)\nfrom nltk.corpus import stopwords\nimport string\nnltk.download(‘stopwords’)\nstopwords_english = stopwords.words(‘english’)\npunctuation = string.punctuation\nstemming - map word to its root form (remove ing, ed, etc.)\nfrom nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\nstemmed_text = [ ]\nfor word in text:\nstem_word = stemmer.stem(word)\nstemmed_text.append(stem_word)\nlowercase - convert all words to lowercase"
  },
  {
    "objectID": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#logistics-regression",
    "href": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#logistics-regression",
    "title": "Text Classification with Logistic Regression",
    "section": "Logistics Regression",
    "text": "Logistics Regression\nLogistics is, in essence, linear regression with sigmoid function (\\(\\sigma\\)).\n\\(h(z) = \\frac{1}{1 + e^{-z}}\\) with \\(z = \\theta^T x\\)\nOR\n\\(\\sigma(x_0 \\theta_0 + x_1 \\theta_1 + x_2 \\theta_2 + x_3 \\theta_3)\\)"
  },
  {
    "objectID": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#training-workflow",
    "href": "posts/2023-07-28-logistic-regression-for-text-classification/index.html#training-workflow",
    "title": "Text Classification with Logistic Regression",
    "section": "Training Workflow",
    "text": "Training Workflow\n\n\n\n\n\n\n\nflowchart TD\n    A[\"Theta\"] --&gt; B[\"h = h(X, Theta)\"]\n    B --&gt; C[\"Nabla = 1/m X^t (h - y)\"]\n    C --&gt; D[\"Theta = Theta - Alpha Nabla\"]\n    D --&gt; E[\"J(Theta)\"]\n    E --&gt; B\n\n\n\n\n\n\n\nLegend:\n\n\\(\\theta\\) = Theta\n\\(\\alpha\\) = Alpha\n\\(\\nabla\\) = Nabla\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TD\n    A[\"Initialize parameters\"] --&gt; B[\"Classify/predict\"]\n    B --&gt; C[\"Get gradient\"]\n    C --&gt; D[\"Update\"]\n    D --&gt; E[\"Get Loss\"]\n    E --&gt; B\n\n\n\n\n\n\n\n\n\n\nTesting (with accuracy)\nTesting can be done via cross-validation data with \\(X_{val}\\), \\(Y_{val}\\) and \\(\\theta\\) on the model to optimize hyper-parameters.\n\n\\(X_{val} Y_{val} \\theta\\)\n\n\\(h(X_{val} . \\theta)\\)\n\\(pred = h(X_{val} . \\theta) &gt;= 0.5\\)\n\n\n\\[\n\\begin{bmatrix}\n0.3 \\\\\n0.8 \\\\\n0.5 \\\\\n\\vdots \\\\\nh_m\n\\end{bmatrix}\n&gt;= 0.5 =\n\\begin{bmatrix}\n0.3 &gt; 0.5 \\\\\n0.8 &gt; 0.5 \\\\\n0.5 &gt; 0.5\\\\\n\\vdots \\\\\npred_m &gt; 0.5\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 \\\\\n1 \\\\\n1 \\\\\n\\vdots \\\\\npred_m\n\\end{bmatrix}\n\\]\n\\[\nAccuracy \\rightarrow \\sum_{i=1}^{m} \\frac{ (pred^{(i)} == y_{val}^{(i)}) }{m}\n\\]\nCost Function\nMakes use of a cost function J composed by 2 parts: * left part (yellow) is relevant when \\(y(i) == 1\\) * right part (blue) is relevant when \\(y(i) == 0\\)\n\\[\nJ(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} log(h(x^{(i)}, \\theta)) + (1 - y^{(i)}) log(1 - h(x^{(i)}, \\theta))   \n\\]\n\n\n\nlogistics cost function\n\n\n\n\nGradient Calculation (Optimization)\nGradient is calculated to adjust logistics-regression parameters during training (see flow below):\n\\[\nRepeat \\{\n\\theta_j = \\theta_j - \\alpha \\frac{\\partial }{\\partial \\theta_j} J(\\theta)\n\\}\n\\]\nFor all \\(j\\), calculate derivatives:\n\\[\nRepeat \\{\n\\theta_j = \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^{m} (h(x^{(i)}, \\theta) - y^{(i)}) x_j^{(i)}\n\\}\n\\]\nDerivative calculation can be summarized as: (with vectors)\n\\[\n\\theta = \\theta - \\frac{\\alpha}{m} X^{T} (H(X, \\theta) - Y)\n\\]\nWith cost function as:\n\\[\n\\partial J(\\theta) = \\frac{1}{m} . X^T . (H(X, \\theta) - Y)\n\\]"
  },
  {
    "objectID": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html",
    "href": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html",
    "title": "Extremely Short Introduction for Ruby on Rails",
    "section": "",
    "text": "This file contains brief descriptions of a Ruby on Rails project.\n\n\nHere a list of the most relevant rails command-line programs organized by task:\n\nStarting a Rails Project: rails \nExecuting a Rails Project: ruby script\\server ( on application directory )\nGenerating a new Model: ruby script\\generate model \nGenerating a new Controller: ruby script\\generate controller \n\n\n\n\napp\nHolds all the code that’s specific to this particular application.\napp/controllers\nHolds controllers that should be named like weblogs_controller.rb for automated URL mapping. All controllers should descend from ApplicationController which itself descends from ActionController::Base.\napp/models\nHolds models that should be named like post.rb.\nMost models will descend from ActiveRecord::Base.\napp/views\nHolds the template files for the view that should be named like weblogs/index.erb for the WeblogsController#index action. All views use eRuby syntax.\napp/views/layouts\nHolds the template files for layouts to be used with views. This models the common header/footer method of wrapping views. In your views, define a layout using the layout :default and create a file named default.erb. Inside default.erb, call &lt;% yield %&gt; to render the view using this layout.\napp/helpers\nHolds view helpers that should be named like weblogs_helper.rb. These are generated for you automatically when using script/generate for controllers. Helpers can be used to wrap functionality for your views into methods.\nconfig\nConfiguration files for the Rails environment, the routing map, the database, and other dependencies.\ndb\nContains the database schema in schema.rb. db/migrate contains all the sequence of Migrations for your schema.\ndoc\nThis directory is where your application documentation will be stored when generated using rake doc:app\nlib\nApplication specific libraries. Basically, any kind of custom code that doesn’t belong under controllers, models, or helpers. This directory is in the load path.\npublic\nThe directory available for the web server. Contains subdirectories for images, stylesheets, and javascripts. Also contains the dispatchers and the default HTML files. This should be set as the DOCUMENT_ROOT of your web server.\nscript\nHelper scripts for automation and generation.\ntest\nUnit and functional tests along with fixtures. When using the script/generate scripts, template test files will be generated for you and placed in this directory.\nvendor\nExternal libraries that the application depends on. Also includes the plugins subdirectory. This directory is in the load path.\n\n\n\nThe application directory is structured like below:\napp\n|-controllers\n|-models\n|-views\nThe fastest way to generate a complete crud for a model is to generate a controller with the scaffold option:\n&gt; script/generate scaffold blog title:string content:text date_created:datetime\nAfter understanding of ruby-on-rails it is considered better practice to generate models, views and controllers separately:\n\nTo generate a blog controller, one must type:\n\n &gt; script/generate controller blog\n Result: a BlogController class will be generated at app/controllers in BlogController.rb\n\nTo generate a blog model, one must type:\n\n &gt; script/generate model blog\n Result: a Blog class will be generated at app/model in blog.rb\n\nviews can not be generated, you have to go to app/views/blog and create a blog.html.erb.\n\nViews for BlogController are automatically assigned in app/views/blog by name convention. ( Since BlogController will have a blog directory in app/views ).\nViews in app/views/blog, must have a *.html.erb extension and an index.html.erb must be created for initial page. Other auxiliary pages can be created in the same directory with different names.\nIn order to add/remove/update models fields, one must only update the corresponding table in the data model only. After that the following command should be executed to update the models in Ruby-on-Rails:\n&gt; rake db:migrate"
  },
  {
    "objectID": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html#important-rails-commands",
    "href": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html#important-rails-commands",
    "title": "Extremely Short Introduction for Ruby on Rails",
    "section": "",
    "text": "Here a list of the most relevant rails command-line programs organized by task:\n\nStarting a Rails Project: rails \nExecuting a Rails Project: ruby script\\server ( on application directory )\nGenerating a new Model: ruby script\\generate model \nGenerating a new Controller: ruby script\\generate controller"
  },
  {
    "objectID": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html#directory-contents",
    "href": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html#directory-contents",
    "title": "Extremely Short Introduction for Ruby on Rails",
    "section": "",
    "text": "app\nHolds all the code that’s specific to this particular application.\napp/controllers\nHolds controllers that should be named like weblogs_controller.rb for automated URL mapping. All controllers should descend from ApplicationController which itself descends from ActionController::Base.\napp/models\nHolds models that should be named like post.rb.\nMost models will descend from ActiveRecord::Base.\napp/views\nHolds the template files for the view that should be named like weblogs/index.erb for the WeblogsController#index action. All views use eRuby syntax.\napp/views/layouts\nHolds the template files for layouts to be used with views. This models the common header/footer method of wrapping views. In your views, define a layout using the layout :default and create a file named default.erb. Inside default.erb, call &lt;% yield %&gt; to render the view using this layout.\napp/helpers\nHolds view helpers that should be named like weblogs_helper.rb. These are generated for you automatically when using script/generate for controllers. Helpers can be used to wrap functionality for your views into methods.\nconfig\nConfiguration files for the Rails environment, the routing map, the database, and other dependencies.\ndb\nContains the database schema in schema.rb. db/migrate contains all the sequence of Migrations for your schema.\ndoc\nThis directory is where your application documentation will be stored when generated using rake doc:app\nlib\nApplication specific libraries. Basically, any kind of custom code that doesn’t belong under controllers, models, or helpers. This directory is in the load path.\npublic\nThe directory available for the web server. Contains subdirectories for images, stylesheets, and javascripts. Also contains the dispatchers and the default HTML files. This should be set as the DOCUMENT_ROOT of your web server.\nscript\nHelper scripts for automation and generation.\ntest\nUnit and functional tests along with fixtures. When using the script/generate scripts, template test files will be generated for you and placed in this directory.\nvendor\nExternal libraries that the application depends on. Also includes the plugins subdirectory. This directory is in the load path."
  },
  {
    "objectID": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html#how-does-model-view-and-controller-relate-to-each-other",
    "href": "posts/2008-12-26-extremely-short-introduction-for-ruby-on-rails/index.html#how-does-model-view-and-controller-relate-to-each-other",
    "title": "Extremely Short Introduction for Ruby on Rails",
    "section": "",
    "text": "The application directory is structured like below:\napp\n|-controllers\n|-models\n|-views\nThe fastest way to generate a complete crud for a model is to generate a controller with the scaffold option:\n&gt; script/generate scaffold blog title:string content:text date_created:datetime\nAfter understanding of ruby-on-rails it is considered better practice to generate models, views and controllers separately:\n\nTo generate a blog controller, one must type:\n\n &gt; script/generate controller blog\n Result: a BlogController class will be generated at app/controllers in BlogController.rb\n\nTo generate a blog model, one must type:\n\n &gt; script/generate model blog\n Result: a Blog class will be generated at app/model in blog.rb\n\nviews can not be generated, you have to go to app/views/blog and create a blog.html.erb.\n\nViews for BlogController are automatically assigned in app/views/blog by name convention. ( Since BlogController will have a blog directory in app/views ).\nViews in app/views/blog, must have a *.html.erb extension and an index.html.erb must be created for initial page. Other auxiliary pages can be created in the same directory with different names.\nIn order to add/remove/update models fields, one must only update the corresponding table in the data model only. After that the following command should be executed to update the models in Ruby-on-Rails:\n&gt; rake db:migrate"
  },
  {
    "objectID": "posts/2006-11-09-delphi-for-oo-programmers/index.html",
    "href": "posts/2006-11-09-delphi-for-oo-programmers/index.html",
    "title": "Delphi for OO Programmers",
    "section": "",
    "text": "I just came from a presentation about Borland products.\nOne of the speakers were showing a piece of Delphi code to explain his idea about object oriented programming and multi-tiered application for Delphi.\nThe Delphi syntax for declaring classes is very bad. Instead of using a syntax similar to what we can find in C++, Java or C# there were strange reserved words. For declaring a Person class, one must code:\n    type Person = class\n      private\n        name : string;\n      end;\n    end;\nTo inherit from a Person it should be something like:\n    type SpecialPerson = class(Person)\n      ......\n    end;\nAfter that in the beginning, the speaker said the “some people” say that OO programming is about, for example, creating a Person class, adding methods to manipulate data, using the instance to perform business logic and then saving to the database. He said that is not the only way and this is just the Java way to build OO systems.\nAt this point I turned off my attention from the presentation for a while and I started wondering if there are other ways to build OO systems.\nWhat he was calling OO programming was a class with lots of static methods responsible for executing a piece of the system. There was a method for inserting a person, erasing a person, calculating a salary, inserting a document, etc.\nWell I would say this is a Service Class but that doesn’t mean that this is a OO system. A lot of people say that because they have declared a class or interface they can assume they are programming using the OO paradigm. A paradigm is not only using objects but a way of thinking and an object oriented system is one that was designed as a collection of objects exchanging information between them by using methods.\nI have heard a lot of people saying that and it is almost rare to find someone that really understans what OO means. At least here where I live in Brazil. I don’t think the programmers must know about OO paradigm but they must admit when they don’t know about a subject and should give the adequate name to the methodology they are working with. In that case above of the Delphi guy, I would say procedural paradigm.\nI also got to the conclusion that a programming language like Delphi was not meant to use OO although it supports this paradigm."
  },
  {
    "objectID": "posts/2008-11-23-generating-software-documentation-from-unit-tests/index.html",
    "href": "posts/2008-11-23-generating-software-documentation-from-unit-tests/index.html",
    "title": "Generating Software Documentation from Unit Tests",
    "section": "",
    "text": "In the beginning of my career as a software developer I participated in two software projects with the traditional approach of document-first and code later. It didn’t take too much time for me to realize this was a not a good aproach. We passed months capturing requirements and writing use cases just to find later that many use cases was actually different from what the stakeholders needed and many requirements have changed.\nThen I came across with agile software development. The idea behind made perfect sense for me and some work colleagues and we started to introduce slowly this new paradigm in our department. Projects that lasted 1 year ( yes ! 1 year ) or more now lasted only a couple of months. Besides that because we were demonstrating the software every week or two to the stakeholders and thus we had feedback often from them.\nThis made us more productive and the final product (the software!) gained more quality and more confidence. But what happened to our business documentation ? We didn’t drop a line of it.\nMany agilists advocate that agile software development is about absence of documentation. Recently many agilists say it is not removing documentation but that it is seen from a different perspective from document-oriented traditional approach. Only the real necessary documentation is produced. Although it sounds perfectly reasonable we still need a way to document business rules for the IT sector managers and also stakeholders. They couldn’t read and understand these rules directly from the source-code since they were not programmers or technicians. So I started to think of a way to automatically generate this documentation.\nI was talking to Anselmo from Siemens and he gave me an interesting idea: Automatic generation of business documentation from unit tests. I started thinking how could I implement this alternative in our software architecture model where we have a service class for each use case and I got to the idea below:\nFor a Client Registration use case we could have the following unit tests:\n[TestFixture][BusinessRules] // Business rule attribute means this test must be documented\nclass Client_Registration_Use_Case\n{ \n   [Test]\n   void Normal_Flow__Check_if_name_is_not_null() { ... }\n\n   [Test]\n   void Normal_Flow__Check_if_address_is_valid() { ... }\n\n   [Test]\n   void Normal_Flow__Check_if_there_is_another_client_with_same_name() { ... }\n\n   [Test]\n   void Normal_Flow__Save_New_Client() { ... }\n\n   [Test ExpectedException(typeof(NullClientNameException)) ]\n   void Alternative_Flow__If_client_name_is_null_raise_message_to_the_user() { ... }\n\n   [Test ExpectedException(typeof(InvalidClientAddressException)) ]\n   void Alternative_Flow__If_client_address_is_invalid_raise_message_to_the_user() { ... }\n\n   [Test ExpectedException(typeof(ClientNameAlreadyExistsException)) ]\n   void Alternative_Flow__If_another_client_with_the_same_name_was_found_raise_message_to_the_user() { ... }\n}\nAt the end, a script in the continuous integration process can read this file or assembly and transform very easily this information and save to a documentation file such as Docbook, ODT or Word Doc. It is important to note that test methods should be placed in the right order so that the right documentation can be generated. The only work is reading the class and methods names and generate the documentation as follows:\n\n\n\n\n\n\nClient Registration Use Case:\n\n\nNormal Flow:\n\n\n1. Check if name is not null 2. Check if address is valid 3. Check if there is another client with same name 4. Save New Client\n\n\nAlternate Flows:\n\n\n1. If client name is null raise message to the user 2. If client address is invalid raise message to the user 3. If another client with the same name was found raise message to the user\n\n\n\nThis idea has the following advantages:\n\nDocumentation reflects exactly what was implemented in the software code and never gets outdated\nIf a new check or action is needed in a use case documentation, the implementation and NOT documentation is changed\nIn order to update the documentation, new unit tests are required what can force discipline among the programmers\nEvery time a release is generated the entire application documentation is updated since the proper unit tests are written\n\nThere disadvantages as well:\n\nUnit tests become more verbose what can slow down its implementation a little bit\nTest methods descriptions may not reflect the test performed inside\n\nHowever I still believe the benefits are higher and I wonder if someone is not applying this idea since it sounds so simple. If you have any ideas for agile business documentation please get in touch with me."
  },
  {
    "objectID": "posts/2009-08-21-avoid-tall-dao-factories/index.html",
    "href": "posts/2009-08-21-avoid-tall-dao-factories/index.html",
    "title": "Avoid ‘Tall’ DAO Factories",
    "section": "",
    "text": "A “tall” DAO factory can be defined as a big class that contains too much methods for each business class that compounds your domain model.\npublic class DAOFactory\n{\n  IClass1DAO GetClass1DAO() { ... }\n  IClass2DAO GetClass2DAO() { ... }\n  IClass3DAO GetClass3DAO() { ... }\n  IClass4DAO GetClass4DAO() { ... }\n  IClass5DAO GetClass5DAO() { ... }\n  IClass6DAO GetClass6DAO() { ... }\n  IClass7DAO GetClass7DAO() { ... }\n  IClass8DAO GetClass8DAO() { ... }\n  IClass9DAO GetClass9DAO() { ... }\n  IClass10DAO GetClass10DAO() { ... }\n  : : : :\n}\nBesides big, these kind of class should be modified every time a new domain class is added to your system.\nIn order to avoid that to happen, one good option is to use a generic method for all DAO interfaces.\npublic class DAOFactory\n{\n  ICommonDAO GetDAO &lt; I &gt; ( ) where I : ICommonDAO { ... }\n}\nThe action of searching the corresponding DAO interface implementation can be easily achieved by using .NET reflection support for Assemblies and Types."
  },
  {
    "objectID": "posts/2009-06-10-how-the-repository-pattern-works-/index.html",
    "href": "posts/2009-06-10-how-the-repository-pattern-works-/index.html",
    "title": "How the repository pattern works ?",
    "section": "",
    "text": "The classes that represent the elements of a domain must contain all the business logic inside it such as tax calculation, name validation, etc. However in many circumstances it is also necessary to access data in order to complete the business logic inside these classes.\nTake the example below:\nSuppose I want to create an instance from the Client class and that clients must have a name and an address (there may be more information but lets stay with those two data for simplification purposes).\nSo, this could be instantiated like: (C# code)\n// Open database connection (and Begin Transaction)\nSessionManager.Open( );\n: : :\n// Parameters are: name, zipcode, adress number, address complement, country\nClient client = new Client(“New Client”,”12500”,12,“Room 14”,Country.US);\n: : :\n// Close database connection (and Commit Transaction)\nSessionManager.Close( );\nAlthough simple, the line above hides many steps such as:\n\nCheck if client name is valid\n\n\n\nCheck if zipcode exists in the county US\n\n\n\nCheck if address number is correct\n\n\n\nCheck if addres complement id correct\n\n\n\nCheck if there are clients with the same name and address\n\n\n\nProceed with the client creation\n\nHowever in order to complete some of this steps, the Client object should be able to access the data layer and that is the responsibility of the repositories. According to Martin Fowler’s website: Mediates between the domain and data mapping layers using a collection-like interface for accessing domain objects.\nReference: http://www.martinfowler.com/eaaCatalog/repository.html\nIn order to make it possible the code line above, an Address and Client class must be implemented.\nSee full code listing below:\n// Address is a value object used by Client class\npublic class Address\n{\n  public Address(string zipCodeNumber,int number,string addrComplement)\n  {\n    // Check if zipcode number exists in the country\n    // (ZipCode Repository uses SessionManager inside it)\n    IZipCodeRepository zipCodeRepository = RepositoryManager.GetRepository( );\n    ZipCode zipCode = zipCodeRepository.Get(zipCodeNumber,country);\n    if (zipCode == null) { throw new NonExistentZipCodeException(zipCodeNumber,country);\n    // Check if address number is correct\n    if  (number &lt;= 0) { throw new InvalidAddressNumberException(number); }               \n    // Check if address complement is correct\n    if (complement.Trim( ) == string.Empty) { throw new  InvalidAddressComplementException(addrComplement)); }\n    // Sets values\n    this._zipCode = zipCode;\n    this._number = number;\n    this._complement = complement;\n  }\n  private ZipCode _zipCode = null;\n  public ZipCode ZipCode get { return _zipCode; }\n  private int _number = 0;\n  public int Number { get { return _number; } }\n  private string _complement = string.Empty;\n  public string Complement { get { return _complement; } }\n}\n\n// Now the Client class\npublic class Client\n{\n  private long _id;\n  public long Id { get { return id; } set { this.id = value; } }\n  private string _name = string.Empty;\n  public Name\n  {        \n    get { return _name; }  \n    // Check if name is valid    \n    set\n    {\n      if (name.Trim( ) == string.Empty) { throw new InvalidNameException(); }               \n      // Check if there are Clients with same name and address               \n      IClientRepository clientRepository = RepositoryManager.GetRepository();\n      bool exists = clientRepository.ClientExists(name,zipCodeNumber,number,addrComplement,country);\n      if (exists) { throw new ClientExistsException( ); }\n      this._name = value;         \n     }\n  }\n  private Address _address;\n  public Address { get { return _address; } }\n  public Client(string name,string zipCodeNumber,int number,string addrComplement,Country country)\n  {       \n    // Creates a Client\n    this.Address = new Address(zipCodeNumber,number,addrComplement,country);\n    this.Name = name;     \n  }\n}\nRepositories have at least two advantages:\n\nIt removes data specific code from the domain classes which are concerned only about business logic\n\n\n\nIt allows unit tests since repositories are referred as interfaces in domain classes and thus fake repositories can be created without depend on database connection"
  },
  {
    "objectID": "posts/2007-12-03-choosing-the-right-primary-keys/index.html",
    "href": "posts/2007-12-03-choosing-the-right-primary-keys/index.html",
    "title": "Choosing the Right Primary Keys",
    "section": "",
    "text": "One of the most common data modeling is the use of composite keys and natural keys as primary keys to identify tables in the database.\nComposite-key tables use more than one key to identify a row while natural keys use domain information to identify a row such as Social Security Number to identify a Person. In most cases a composite-key is actually a composite-natural-key.\nHowever these tecniques are not consider good practices to choose the table primary keys due to the following factors:\nBusiness Rules change over time but primary keys don’t\n\nBusiness rules are dynamic but primary keys are static until you update the database model what can cost a lot time and effort if not impossible. For example if you identify a Client with a Social Security number you may not be able to identify a foreign Person if needed or maybe the government can decide to use the same Social Security Number for more than one person. This lack of capacity to change the database model can reduce significantly the agility of an organization to adapt its business model to new kind of reality what reduces its capacity to compete with other organizations.\n\n\nFigure 1 - Table identified by a natural key\n\n\n\n\n\n\nComposite Keys require more work\n\nIt is necessary to write longer SQL queries since you have to use all the primary keys to join this table to another one.\nselect cli.name, pd.description, sa.date, sa.quantity from Client cli inner join Sales sa on ( cli.socialSecurityNumber = sa.socialSecurityNumber ) inner join Product pd on ( sa.idProductType = pd.idProductType and sa.vendorRegistration = pd.vendorRegistration ) where sa.date &gt;= ‘2007-12-01’\n\nMake the Database model less readable\n\nComposite keys spread to other tables as a foreign key and are added to other foreign composite-key columns. In some cases where composite-keys are widely used there are much more composite-key columns in a table than useful information.\n\n\nFigure 2 - Only date and quantity are Sales columns\n\n\nthe rest are inherited primakey keys from other tables\n\n\n\n*\n*\n\nIn the other hand one of the stronger arguments in favor of composite and natural-keys is that they provide a safer way to restrict data integrity avoiding certain columns in a table to repeat while with a single primary key can not garantee this.\nBut many people forget that this data integrity can be done in single-primary tables too by using alternate keys. With alternate keys you can choose a group of columns in a table make them unique just like a composite-key would do it.\nIn order to present this idea in more details below there are two examples, one with the traditional composite-key and natural keys aproach and the other with the proposed idea of using single primaty keys ( non-natural keys ) and alternate keys.\n*\n*\n\nFigure 3- Data model example that makes use of natural-keys\n\n\n\nFigure 4 - Data model example with single primary keys and alternate keys"
  },
  {
    "objectID": "posts/2009-03-14-net-using-generics-to-avoid-repetition-in-domain-classes/index.html",
    "href": "posts/2009-03-14-net-using-generics-to-avoid-repetition-in-domain-classes/index.html",
    "title": ".NET: Using Generics to avoid repetition in Domain Classes",
    "section": "",
    "text": "In classical object oriented methodologies or new-old-ones such as Domain Driven Design, the domain layer classes have persistent methods that reference its correpondent repository.\nGenerally this is the format:\npublic class SomeDomainClass\n{\n    public SomeDomainClass(string description) { ... }\n\n    private long _id;\n    public long Id { set {...} get{...} }\n    private string _description;\n    public string Description { set{...} get{...} }\n\n    private static ISomeDomainClassRepository repository = RepositoryFactory.Get();\n\n    public void Save() { repository.Save(this); }\n    public void Remove() { repository.Remove(this); }\n    public static SomeDomainClass GetById(long id) { return repository.GetById(id); }\n    public static IList GetByDescriptionPart(string descriptionPart) { \n        return repository.GetBydescriptionPart(descriptionPart); \n    }\n}\nIf by convention we define Id property, Save, Remove and GetById methods as default methods.\nThen they will repeat for every Domain class. In .NET we can avoid this problem with generic programming:\npublic class PersistentBase where classType:class\n{\n    private idType _id;\n    public idType Id { protected set { this._id = value; } get { return this._id; } }\n\n    private static iRepositoryInterface repository = Repository.GetRepository();\n\n    public void Save() { repository.Save(this); }\n    public void Remove() { repository.Remove(this); }\n    public static classType GetById(idType id) { return repository.GetById(id); }   \n}\nThus, with the help of the PersistentBase, SomeDomainClass would be:\npublic class SomeDomainClass : PersistentBase\n{\n    public SomeDomainClass(string description) { ... }\n\n    private string _description;\n    public string Description { set{...} get{...} }\n\n    // Only specific data method will remain\n    public static IList GetByDescriptionPart(string descriptionPart) { \n        return repository.GetBydescriptionPart(descriptionPart);\n    }\n}"
  },
  {
    "objectID": "posts/2007-05-09-my-first-big-enterprise-system-with-nhibernate/index.html",
    "href": "posts/2007-05-09-my-first-big-enterprise-system-with-nhibernate/index.html",
    "title": "My First Big Enterprise System with NHibernate",
    "section": "",
    "text": "We just finished to deliver our first big .NET system with a 4-Layered Architecture and domain objects. The proof-of-concepts is done also for big systems.\nBecause we use a 4-Layered Architecture, the same business rules describe in the Task Layer (or Service Layer, as you wish) are applied to both the desktop and the web versions of the application.\nNHibernate has also proven its value showing that it has enough performance for any kind of systems. I am anxious to start building other layered object-oriented systems like this."
  },
  {
    "objectID": "posts/2010-02-24-name-convention-for-object-oriented-apps/index.html",
    "href": "posts/2010-02-24-name-convention-for-object-oriented-apps/index.html",
    "title": "Name Convention for Object Oriented Apps",
    "section": "",
    "text": "Some time ago I came across with a question about naming conventions for different parts of the software: UI, Service, Entities, etc. I decided to share some of the conventions I have been using.\n\n\nNaming Convention: ( Most used ):\n- Entities: As it is part of the domain package, no prefixes or suffixes here: Ex: Car, Client, etc.\n- Repository: Usually a suffix Repository. Ex: ClientRepository, CarRepository, etc.\n- ValueObject: Value objects are part of the domain so it follows entity´s convention. Ex: Money, Address, etc.\n- DTO: Usually a suffix DTO. Ex: ClientRegistrationDTO, CarRentDTO, AddressDTO, etc.\n- Service: Usually a suffix Service. Ex: ClientRegistrationService, CarRentService, etc.\nNamespace Convention: (My Suggestion)\nEntities, ValueObjects, Repositories Interfaces, Domain Services (Domain Layer)\n..Domain.\nEx: Acme.Finantial.Domain.Debt,\n      Acme.HR.Domain.CheckOvertimeService,\n      Acme.Core.Domain.IPersonRepository    \nApplication Services \n..Service.\nEx: Acme.Sales.Service.ClientRegistrationService\nPresentation Layer\n..Presentation.\nEx: Acme.HR.Presentation.IClientRegistrationView, Acme.HR.Presentation.WebClientRegistration\nPersistence Layer\n..Persistence.\nEx: Acme.Core.Persistence.PersonRepositoryImpl (&lt;— implementation in NH, for example)"
  },
  {
    "objectID": "posts/2009-12-26-model-view-controller-with-events-in-net/index.html",
    "href": "posts/2009-12-26-model-view-controller-with-events-in-net/index.html",
    "title": "Model View Controller with Events in .NET",
    "section": "",
    "text": "This is often a confused design pattern and its main purpose is to separate objects that assume different roles in a software.\nThese roles are:\n\n\nmodels - objects that actual execute the system tasks\nviews - objects that display the system data\ncontrollers - objects that capture the user intentions from the view and route to the right actions\n\n\nUsually Views have a reference to the controller however another approach below shows how to decouple the views from the controllers.\nViews can be implemented in several ways depending on the UI library. For that reason, views are better represented as interfaces. However in order to reduce coupling between views and controllers, events can be used in the interface views.\n\nThe example below shows a client registration view:\nusing System;\nnamespace MyController\n{\n  public interface IClientRegistrationView\n  {\n    public long Id { get; set; }\n    public string Name { get; set; }\n    public string Registration { get; set; }\n    public event ClientEventHandler InsertRequested;\n    public event ClientEventHandler UpdateRequested;\n    public event ObjectIdEventHandler&lt;long&gt; RemoveRequested;\n    public event ObjectIdEventHandler&lt;long&gt; RetrieveRequested;\n  }\n}\nSpecific event arguments were also created for the Client Registration View:\n\nClientEventArgs - contains client fields so that it can be sent to the underlying layer.\nObjectIdEventArgs - contains a generic object id for deletion and queries purposes.\n\n\nSee event argument classes below:\n\nusing System;\nnamespace MyController\n{\n  public delegate void ClientEventHandler(object sender, ClientEventArgs e);\n  public class ClientEventArgs : EventArgs\n  {\n  public long Id { get; set; }\n  public string Name { get; set; }\n  public string Registration { get; set; }\n  }\n}\nusing System;\nnamespace MyController\n{\n  public delegate void ObjectIdEventHandler&lt;T&gt; (object sender, ObjectIdEventArgs&lt;T&gt; e);\n  public class ObjectIdEventArgs&lt;T&gt; : EventArgs\n  {\n    public T Id { get; set; }\n  }\n}\n\nThe controller will have a reference to a view (an interface) and it will access the view´s data fields for the client which is Id, Name and Registration.\nBesides that, the controller will also be told to trigger actions by listening to the view´s events.\nIn this example, the service acts as if it was the model of the system.\n\nusing System;\nusing MyService;\nnamespace MyController\n{\n  public class ClientRegistrationController\n  {\n    private IClientRegistrationView View { get; set; }\n    private ClientRegistrationService Service { get; set; }\n    public ClientRegistrationController(IClientRegistrationView view)\n    {\n      View = view;\n      View.InsertRequested += new ClientEventHandler(View_InsertRequested);\n      View.UpdateRequested += new ClientEventHandler(View_UpdateRequested);\n      View.RemoveRequested += new ObjectIdEventHandler&lt;long&gt; (View_RemoveRequested);\n      View.RetrieveRequested += new ObjectIdEventHandler&lt;long&gt; (View_RetrieveRequested);\n      Service = new ClientRegistrationService();   \n    }\n    void View_InsertRequested(object sender, ClientEventArgs e)\n    {\n      ClientDTO dto = new ClientDTO() { Id = e.Id, Name = e.Name, Registration = e.Registration };\n      Service.Insert(dto);\n      this.View.Id = dto.Id;\n    }\n    void View_UpdateRequested(object sender, ClientEventArgs e)\n    {\n      Service.Update(new ClientDTO() { Id = e.Id, Name = e.Name, Registration = e.Registration });\n    }\n    void View_RemoveRequested(object sender, ObjectIdEventArgs&lt;long&gt; e)\n    {\n      Service.Remove(e.Id);\n    }\n    void View_RetrieveRequested(object sender, ObjectIdEventArgs&lt;long&gt; e)\n    {\n      ClientDTO dto = Service.Retrieve(e.Id);\n      this.View.Id = dto.Id;\n      this.View.Name = dto.Name;\n      this.View.Registration = dto.Registration;\n    }\n  }\n}\nAs it can be seen above, the View doesn´t need to have a reference to the Controller. The view is totally decoupled form the controller but it can communicate with it by listening to the events."
  },
  {
    "objectID": "posts/2011-02-27-publishing-clickonce-winforms-applications-with-command-line-msbuild/index.html",
    "href": "posts/2011-02-27-publishing-clickonce-winforms-applications-with-command-line-msbuild/index.html",
    "title": "Publishing ClickOnce winforms applications with command-line MSBuild",
    "section": "",
    "text": "One of the most interesting characteristics of tools such as CCNet and Nant is the automated deploy. I found many examples of how to publish an application with pre-configured projects with click-one but I wanted to do it different. In order to make the project file cleaner the approach was to remove all click-once configurations from the project(*.csproj) so that command-line MSBuild will take care of publication configuration in a NAnt script. After some full-days of research, I found the solution below. I hope it helps in your project.\n&lt;exec program=\"${dotnetFrameworkDir}\\MSBuild.exe\"&gt;\n  &lt;arg value=\"${basePath}\\MyProject\\MyProject.csproj\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/target:publish\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:IsWebBootstrapper=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:SignManifests=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:ManifestKeyFile=${basePath}\\MyProject\\MyCertificate.pfx\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:TargetZone=LocalIntranet\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:GenerateManifests=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:PublishUrl=${clickOnceDir}\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:Install=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:InstallFrom=Web\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:UpdateEnabled=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:UpdateRequired=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:InstallUrl=http://myPublishUrlAddress\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:TargetCulture=pt-BR\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:ProductName=MyProject\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:PublisherName=MyCompany\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:MinimumRequiredVersion=${CCNetLabel}\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:CreateWebPageOnPublish=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:WebPage=${webPage}\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:OpenBrowserOnPublish=false\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:ApplicationRevision=17\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:ApplicationVersion=${CCNetLabel}\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:CreateDesktopShortcut=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:PublishWizardCompleted=true\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:BootstrapperComponentsLocation=Absolute\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:BootstrapperComponentsUrl=${bootstrapperUrl}\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:GenerateBootstrapperSdkPath=${pathBootStrapper}\"&gt;&lt;/arg&gt;\n  &lt;arg value=\"/p:UpdateUrlEnabled=false\"&gt;&lt;/arg&gt;\n&lt;/exec&gt;"
  },
  {
    "objectID": "posts/2010-05-08-test-driven-development-best-practices/index.html",
    "href": "posts/2010-05-08-test-driven-development-best-practices/index.html",
    "title": "Test-Driven-Development Best Practices",
    "section": "",
    "text": "I recently read a very intersting conversation in StackOverflow.com about test-driven development. I found it very instersting and the principles can be summarized as follows: (not ordered by importance)\n\n1. Write the test first, then the code. Reason: This ensures that you write testable code and that every line of code gets tests written for it. \n\n\n2. Design classes using dependency injection. Reason: You cannot mock or test what cannot be seen. \n\n\n3. Separate UI code from its behavior using Model-View-Controller or Model-View-Presenter. Reason: Allows the business logic to be tested while the parts that can’t be tested (the UI) is minimized. \n\n\n4. Do not write static methods or classes. Reason: Static methods are difficult or impossible to isolate and Rhino Mocks is unable to mock them. \n\n\n5. Program off interfaces, not classes. Reason: Using interfaces clarifies the relationships between objects. An interface should define a service that an object needs from its environment. Also, interfaces can be easily mocked using Rhino Mocks and other mocking frameworks. \n\n\n6. Isolate external dependencies. Reason: Unresolved external dependencies cannot be tested. \n\n\n7. Mark as virtual the methods you intend to mock. Reason: Rhino Mocks is unable to mock non-virtual methods.\n\n8. Use creational design patterns. This will assist with DI, but it also allows you to isolate that code and test it independently of other logic.\n\n\n9. Write tests using Bill Wake’s Arrange/Act/Assert technique. This technique makes it very clear what configuration is necessary, what is actually being tested, and what is expected.\n\n\n10. Don’t be afraid to roll your own mocks/stubs. Often, you’ll find that using mock object frameworks makes your tests incredibly hard to read. By rolling your own, you’ll have complete control over your mocks/stubs, and you’ll be able to keep your tests readable. (Refer back to previous point.)\n\n\n11. Avoid the temptation to refactor duplication out of your unit tests into abstract base classes, or setup/teardown methods. Doing so hides configuration/clean-up code from the developer trying to grok the unit test. In this case, the clarity of each individual test is more important than refactoring out duplication.\n\n\n12. Implement Continuous Integration. Check-in your code on every “green bar.” Build your software and run your full suite of unit tests on every check-in. (Sure, this isn’t a coding practice, per se; but it is an incredible tool for keeping your software clean and fully integrated.)\n\n Reference: http://stackoverflow.com/questions/124210/best-practices-of-test-driven-development-using-c-and-rhinomocks"
  },
  {
    "objectID": "posts/2010-05-09-using-fluent-builder-pattern-to-configure-test-objects/index.html",
    "href": "posts/2010-05-09-using-fluent-builder-pattern-to-configure-test-objects/index.html",
    "title": "Using Fluent Builder Pattern to Configure Test Objects",
    "section": "",
    "text": "Depending on the complexity of the domain model, configuring mock objects for specific cenarios can make the resulting test code to get messy.\nConsider the situation below with C#, NUnit and Moq framework\n[Test]\n[ExpectedException(InvalidPaymentAgreementException)]\npublic void PaymentAgreementMustNotBeCreatedWhenThePaymentOptionIsNotValidForTheDebtType()\n{\n  Mock somePaymentOptionMock = new Mock();\n  Mock debTypeMock = new Mock();\n  debtTypeMock\n    .Setup(debtType.GetPaymentOptions())\n    .Returns(new List(){somePaymentOptionMock.Object});\n\n  Mock anotherPaymentOptionMock = new Mock();\n\n  Mock debtMock = new Mock();\n  debtMock.Setup(debt.DebtType).Returns(debTypeMock.Object);            \n\n  PaymentAgreement paymentAgreement = new PaymentAgreement(\n    new PaymentAgreementCreationParameter()\n    {\n      AgreementYear = SystemDate.Get().Value.Year,\n      AgreementNumber = 1,\n      AgreementCreationDate = SystemDate.Get().Value.Date,\n      NumberOfInstallments = 1,\n      AgreementValue = 100.0m,\n      Debts = new List() { debtMock.Object },\n      SelectedPaymentOption =  anotherPaymentOptionMock.Object\n    });\n}\nA developer who reads the unit test can take a consirable amount of time to understand what is actually being tested even if a well-designed mock framework such as Moq is in use. Most of this work is about configuring mock objects. Besides the code size, the unit test doesn´t speak the language of the domain (business) and thus it becomes a mass of meaningless mock configuration.\nI am on my way to learn how to apply TDD effectvely in software development and I quickly realized that the quality of unit tests are very important in order to this kind of methodology to succeed.\nAccidentally some days I read an interesting post from Andrian about Rich Domain Tests at http://adrianhummel.wordpress.com/ and I decided to apply his idea.\nAfter reading his post I got to the conclusion that one way to solve or at least minimize this unit-test-messy-code-problem was by using a fluent builder pattern to configure mock objects by using a builder whose interface could be describe how I am configuring a mock object with an interface closer to domain language.\nThe unit test below is a rewritten from the example above with the concepts described here:\n[Test]\n[ExpectedException(InvalidPaymentAgreementException)]\npublic void PaymentAgreementMustNotBeCreatedWhenThePaymentOptionIsNotValidForTheDebtType()\n{\n  PaymentOption somePaymentOption = PaymentOptionMockBuilder\n                                    .Begin()\n                                    .BuildPaymentOption();\n\n  DebtType debtType = DebtTypeMockBuilder\n                      .Begin()  \n                      .AddPaymentOptionOf(somePaymentOption)\n                      .BuildDebtType();\n            \n  PaymentOption anotherPaymentOption = PaymentOptionMockBuilder\n                                       .Begin()\n                                       .BuildPaymentOption();          \n            \n  Debt debt = DebtMockBuilder\n              .Begin()\n              .WithDebtTypeOf(debtType)\n              .BuildDebt();\n\n  PaymentAgreement paymentAgreement = new PaymentAgreement(\n    new PaymentAgreementCreationParameter()\n    {\n      AgreementYear = SystemDate.Get().Value.Year,\n      AgreementNumber = 1,\n      AgreementCreationDate = SystemDate.Get().Value.Date,\n      NumberOfInstallments = 1,\n      AgreementValue = 100.0m,\n      Debts = new List &lt Debt &gt () { debt},\n      SelectedPaymentOption =  anotherPaymentOption\n    });\n\n}\nThe fluent builder for Debt is DebtMockBuilder and can be programmed as follows:\n    public class DebtMockBuilder\n    {\n        private Mock _debtMock;\n\n        public static DebtMockBuilder Begin()\n        {\n            DebtMockBuilder builder = new DebtMockBuilder();\n            builder._debtMock = new Mock();\n            return builder;\n        }\n\n        public Debt BuildDebt()\n        {\n            return _debtMock.Object;\n        }\n\n        public DebtMockBuilder WithDebtTypeOf(DebtType debtType)\n        {\n            this._debtMock.Setup(debt =&gt; debt.DebtType).Returns(debtType);\n            return this;\n        }\n    }\nPaymentOptionMockBuilder follows the same idea.\nAlthough I see that some improvements are needed I could see the following advantages from fluent mock builders:\n\nThe test code was easier to understand because domain terms were applied instead of specific API language.\nSpecific mock framework calls were encapsulated which theoretically can let programmers to use another mock framework in other projects or using more than one mock framework in the same test (I dont know why someone would do such a thing…).\nFinally mock configuration becomes more flexible since existing methods don´t have to be modified to include new configuration but only a new configuration method is needed. Thus mock configuration can evolve as needed without loosing the domain interface."
  },
  {
    "objectID": "posts/2015-07-16-efficient-unit-test-in-cnet/index.html",
    "href": "posts/2015-07-16-efficient-unit-test-in-cnet/index.html",
    "title": "Efficient Unit Test in C#.NET",
    "section": "",
    "text": "I consider unit tests one of the most important practices in agile programming.\nAs the name stated, unit tests check the behaviour of the smaller part of an object what can be a constructor, method or property.\n[TestFixture]\npublic class SomeTest {\n  [Test]\n  public void CheckDiscountCalculation() {\n    Product prod1 = new Product(\"T-Shirt\",125.0d); // description and price\n    Product prod2 = new Product(\"Apple\",10.0d);\n    Product prod3 = new Product(\"Pants\",50.0d);\n\n    OrderItem item1 = new OrderItem(prod1,1); // product and quantity\n    OrderItem item2 = new OrderItem(prod2,1);\n    OrderItem item3 = new OrderITem(prod3,1);\n\n    Client client = new Client(\"Jack\");\n\n    Order order = new Order(client);\n    order.AddItem(item1);\n    order.AddItem(item2);\n    order.AddItem(item3);\n\n    decimal discount = order.CalculateDiscount();\n\n    Assert.AreEqual(18.5d, discount);        \n  }\n}\nAlthough the test example above is perfectly possible you can note that much of this test was spent in initializing the neighbour objects before actually testing the discount calculation.\nIn real world tests, this can get much more complicated, with several dependencies around the objects. Besides that it can be even more difficult to initialize objects when they access the database internally even through interfaces.\nIn order to minimize this problem, there are mock frameworks that can be used together with NUnit or your preferred unit testing framework. Basically mock framework can dynamically generate fake objects from class types so that you can focus on testing in your target object.\nIn the example above, the target is the Order. My preferred Mock framework is Moq due to its heavy usage of delegate notations which avoid using magical strings to configure Mock classes and setup methods.\nThe above test now can be rewritten like this:\n[TestFixture]\npublic class SomeTest\n{\n  [Test]\n  public void CheckDiscountCalculation()\n  {\n    Mock prod1Mock = new Mock();\n    // Ignores method implementation and returns 125.0d\n    prod1Mock.Setup(p=&gt;p.Price).Returns(125.0d); \n\n    Mock prod2Mock = new Mock();\n    prod2Mock.Setup(p=&gt;p.Price).Returns(10.0d);\n\n    Mock prod3Mock = new Mock();\n    prod3Mock.Setup(p=&gt;p.Price).Returns(50.0d);\n\n\n    // product and quantity\n    OrderItem item1 = new OrderItem(prod1,1);\n    OrderItem item2 = new OrderItem(prod2,1);\n    OrderItem item3 = new OrderITem(prod3,1);\n\n    Client client = new Client(\"Jack\");\n\n    Order order = new Order(client);\n    order.AddItem(item1);\n    order.AddItem(item2);\n    order.AddItem(item3);\n\n    decimal discount = order.CalculateDiscount();\n\n    Assert.AreEqual(18.5d, discount);        \n  }\n}"
  },
  {
    "objectID": "posts/2011-02-27-iphone-development-to-objective-c-or-not-to-objective-c-/index.html",
    "href": "posts/2011-02-27-iphone-development-to-objective-c-or-not-to-objective-c-/index.html",
    "title": "iPhone Development: to Objective-C or not to Objective-C ?",
    "section": "",
    "text": "When I think of Objective-C, what comes to my mind is a niche programming language for the MacOS and Apple related products. Thus as far as I know this is the only officially supported language to develop products for iPhones, iPods, iPads and so on ….\nOn the other hand I really what to develop apps that will work in Windows, Linux and MacOS, and for this purpose I see two options:\n1) Develop in C/C++ and try to find tools that translate this code to Objective-C and/or MacOS\n2) Use Objective-C to develop any kind of application (at least desktop and mobile apps)"
  },
  {
    "objectID": "posts/2011-02-27-iphone-development-to-objective-c-or-not-to-objective-c-/index.html#developing-portable-iphone-apps-outside-objective-c",
    "href": "posts/2011-02-27-iphone-development-to-objective-c-or-not-to-objective-c-/index.html#developing-portable-iphone-apps-outside-objective-c",
    "title": "iPhone Development: to Objective-C or not to Objective-C ?",
    "section": "Developing portable iPhone apps outside Objective-C",
    "text": "Developing portable iPhone apps outside Objective-C\n\nSwig\nFor the first option, there is swig ( http://www.swig.org/ ) which is a wrapper for C++ to export its classes and/or functions to several languages (Objective-C is a work in progress).\nHowever it doesn´t really solve the problem because there are libraries.\n\n\nMono Touch\nThe Mono Touch ( http://monotouch.net/ ) is probably one of the most interesting project to develop apps for the iPhone without Objective-C. It makes it possible to develop apps with C#.NET. The same Mono project also make it possible to develop apps for Linux. As a consequence, C#.NET could be seriously considered to develop apps for a wide range of platforms. However unlike Mono one must pay to start using it which may not be a problem if you are familiarized with C#.NET.\n\n\nPhoneGap\nAnother options is PhoneGap ( http://www.phonegap.com ) which is an open-source framework whose objective is to let developers to write apps with HTML5+CSS+JavaScript and execute it to the different mobile platforms including iOS."
  },
  {
    "objectID": "posts/2011-02-27-iphone-development-to-objective-c-or-not-to-objective-c-/index.html#objective-c-as-a-portable-programming-language",
    "href": "posts/2011-02-27-iphone-development-to-objective-c-or-not-to-objective-c-/index.html#objective-c-as-a-portable-programming-language",
    "title": "iPhone Development: to Objective-C or not to Objective-C ?",
    "section": "Objective-C as a portable programming language",
    "text": "Objective-C as a portable programming language\nI recently read about he mechanics and philosophy of Objective-C language and I got quite impressed by its features. It is not just C with classes as I heard before, it is actually a powerful dynamic language. Everything is an object including the classes itself what reminds me of Smalltalk, LISP and Python.\nThere are also some options to use Objective-C outside of the Apple ecosystem:\n\nGNU Step\nAs stated in their website ( http://www.gnustep.org/ ) the objective is to create an open version of Cocoa (former NextStep) for several platforms including Linux and Windows.\nBesides porting the API this project also comes with several developer tools such as an IDE named ProjectCenter and a GUI code generator called Gorm."
  },
  {
    "objectID": "posts/2010-06-03-tools-and-utilities-for-the-net-developer/index.html",
    "href": "posts/2010-06-03-tools-and-utilities-for-the-net-developer/index.html",
    "title": "Tools and Utilities for the .NET Developer",
    "section": "",
    "text": "Here is a list I got from the internet that might be useful (at least for a while):\nhttp://geekswithblogs.net/mbcrump/archive/2010/05/25/tools-and-utilities-for-the-.net-developer.aspx"
  },
  {
    "objectID": "posts/2015-01-26-create-an-agnostic-vendor-infrastructure-in-ruby/index.html",
    "href": "posts/2015-01-26-create-an-agnostic-vendor-infrastructure-in-ruby/index.html",
    "title": "Create an Agnostic Vendor Infrastructure in Ruby",
    "section": "",
    "text": "Depending how the code was written adding new services to it can be difficult.\nFor instance, let’s say we are building a rails application that gets integrated to cloud storage vendors.\nA naive implementation would be to directly integrate to a cloud storage specific APIs.\nIn this case when new cloud storage vendors are added it is very probable that several nasty case… when … end statements would be inserted in code.\nWhen a new cloud storage service is added the developer must remember all places where those growing case-like statements are inserted. This makes the system more susceptible to errors due to  changes in several parts of the code. This problem is explained in detail by the shotgun surgery anti-pattern (http://en.wikipedia.org/wiki/Shotgun_surgery)\nThe rest of the system shouldn’t be aware that a new cloudstorage service was added. That is where a combination of design patterns come in handy:\n\na facade to provide a simple interface for cloud storage operations \na service locator to find the right cloud storage adapter\na cloud storage adapters that make each vendor API compliant to a single defined interface that can be understood by the facade\n\n\n1) Cloud Storage Facade\n2) Cloud Storage Adapter Locator\n3) Cloud Storage Adapters\nNote that this combination of patterns can be used to abstract many other types of services. Cloud storage service was just an example used here."
  },
  {
    "objectID": "posts/2007-10-17-less-is-more---dynamically-typed-languages/index.html",
    "href": "posts/2007-10-17-less-is-more---dynamically-typed-languages/index.html",
    "title": "Less is More - Dynamically typed languages",
    "section": "",
    "text": "When I was in the university I learned that strongly typed languages should be preferred since they avoid the programmers from using a certain variable in way that it was not meant to.\nIf I declare “string name;” I know this will accept only strings and will prevent a programmer from assign a number or a boolean value on it.\nBut this seems to be a false concern with the success of other languages such as Python and Ruby.\nThis programming languages are now used to each time more complex software and nobody is complaining about their “dynamic” features.\nThe goal the new development tools are trying to achieve is how can I do my software faster in a clean and organized way. Less is More !"
  },
  {
    "objectID": "posts/2015-07-26-from-static-language-style-api-to-ruby-style-api/index.html",
    "href": "posts/2015-07-26-from-static-language-style-api-to-ruby-style-api/index.html",
    "title": "From static-language style API to Ruby style API",
    "section": "",
    "text": "It has passed some time since I published a Naive_Bayes for text-classifier written in Ruby. At that time the API was designed very much influenced in way I have written a similar classifier in C++. However it was after a looked at the gem Decider that I realized how it was not taking advantage over the dynamic characteristics of Ruby to make Domain-Specific-Language APIs."
  },
  {
    "objectID": "posts/2015-07-26-from-static-language-style-api-to-ruby-style-api/index.html#static-characteristics-of-my-original-ruby-classifier-interface",
    "href": "posts/2015-07-26-from-static-language-style-api-to-ruby-style-api/index.html#static-characteristics-of-my-original-ruby-classifier-interface",
    "title": "From static-language style API to Ruby style API",
    "section": "Static characteristics of my original Ruby classifier interface",
    "text": "Static characteristics of my original Ruby classifier interface\nThe following are the methods that called my attention:\n\nCategory declaration\nUse of add_category method to declare new categories expects a category name and an array of strings as an example.\nclassifier.add_category(name: :not_spam, training_set: [ 'Hi', 'Joe', 'how', 'are', 'you' ])\n\n\nInput classification\nThe classify method makes use of an array of string as input for classification.\ncategory = classifier.classify(['Hi','James','are','you', 'going'])\ncategory.to_s # not_spam"
  },
  {
    "objectID": "posts/2015-07-26-from-static-language-style-api-to-ruby-style-api/index.html#refactoring-to-new-style",
    "href": "posts/2015-07-26-from-static-language-style-api-to-ruby-style-api/index.html#refactoring-to-new-style",
    "title": "From static-language style API to Ruby style API",
    "section": "Refactoring to new style",
    "text": "Refactoring to new style\n\nCategory declaration through method missing and string\nInstead of adding categories with a training set the user should only be required to provide examples to its desired with a dynamically created method which corresponds to a category name.\nclassifier.not_spam &lt;&lt; \"Hi Joe, how are you\"\n\n\nInput classification from string\nInstead of requiring the user to break the string in an array the entire string can be classified. The classifier should also take the responsibility of breaking the string in words.\ncategory = classifier.classify \"Hi James,are you going ?\"\ncategory.to_s # not_spam"
  },
  {
    "objectID": "posts/2009-06-13-agile-modeling-in-software-projects/index.html",
    "href": "posts/2009-06-13-agile-modeling-in-software-projects/index.html",
    "title": "Agile Modeling in Software Projects",
    "section": "",
    "text": "Recently Jeff Sutherland mentioned another certification for software programmers since Scrum does not include software engineer techniques but very present in XP (extreme programming) management. That is probably the reason why many software developers work with Scrum and XP methodologies together.\nHowever although XP is very software-programming oriented it is still not enough to have a good software design in large systems projects. Additionally in many organizations it is very difficult to find a product owner that fully understand the business rules and can manage the software functionalities.\nIn order to efficiently use Scrum, there must be someone responsible for understanding the business. If there is no product owner, one employee must be chosen to study and logically model the business. That is exactly why a good business modeling is imperative before any large software development.\nGood software design and business understanding prevents or reduces significantly re-work tasks. It is considered wasted work since these tasks do not devliver anything useful to the client and often happens when developers did not captured well the business rules.\nThus the following software development process is proposed to match DDD and agile approach. In this software process, there can be product owners, developers and scrum masters just like original Scrum the difference is that before the sprints (see Scrum reference) can start, a long DDD session is necessary in order to produce a good business model.\nBriefly describing the following steps should be taken:\n\nA selected person assumes the role of Product Owner\nProduct Owner becomes responsible for studying and building a business model\n\nProduct Owner writes all the system features using User Stories (from XP)\nProduct Owner schedules a Planning Meeting with the Scrum Master and Developers to present User Stories and the Business Model\nScrum Master schedules a Sprint Meeting with developers to plan the Next Sprint based on the Stories\nDevelopers begin the Sprint (from 1 to 2 weeks)\nScrum Master Organizes Daily Meetings with Developers (just like Scrum)\nAt the end of the Spring, Scrum Master schedules a Weekly Meeting to present the system to the Product Owner but it also includes the developers of the project who makes considerations about the system presented\nScrum Master organized a Retrospective Meeting with the developers to discuss what went wrong or right with the Sprint and then they start planning the next Sprint.\nGo to Step 6 until Product Owner gets satisfied"
  },
  {
    "objectID": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html",
    "href": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html",
    "title": "Express business language in your code with use cases",
    "section": "",
    "text": "Use cases are a very important element in UML that addresses the functional aspect of a software. The use case diagram shows how the different system functionalities are associated to the different users in a system which are referred as actors.\n\nThe specific user kind is referred in UML as an actor. Note in the diagram above that a system can have several kinds of actors and an actor can be specialized from an existing one. For instance both Student and Teacher are specialized from School Member. This means they can also execute the same use cases from School Member which can serve to group common functionalities.\nAlso the objective of a use case is not just to describe a feature but to describe a business flow using a high level language that can be understood by the business expert on how a specific kind of user can achieve his goals.\nFor instance the “Enroll in Subject” use case can be described as follows:\n====================================================  \n**Project:** My School System  \n  \n**Subdomain:** Enrollment  \n  \n**Title:**  Enroll in Subject  \n  \n**Description:** Describes how a subject can be enrolled to a student.  \n  \n**Precondition:** student must be authenticated by the system.  \n  \n**Normal Flow:**  \n\n\n-   (n1) System lists all available subjects which were not enrolled or\n    completed by this student\n-   (n2) Student selects a subject\n-   (n3) System verifies if the subject is open for enrollment\n-   (n4) if subject is still open system enrolls student to it \\[a1\\]\n-   (n5) System sends a message to the student stating that the\n    enrollment was successful\n\n  \n**Alternative Flows:**  \n  \n&lt;u&gt;\\[a1\\] Subject is not open for enrollments:&lt;/u&gt; System sends a\nmessage to the user stating that the subject is not open for\nenrollment.  \n  \n**Integrity Constraints:**  \nStudent should not enroll in a subject he/she completed before.  \n  \n====================================================  \nUse cases popular in the 90s and begining of 2000s almost disappeared after that and recently there has been some interest in it perhaps because software engineers have identified a need to better understand the business flow in more details than what can be found in use cases.\nHowever use cases present many advantages such as:\n\nCommon language for engineers and domain experts - document can be the bridge between engineers and domain experts since it talks the language of the business in a structured way.\nTechnology independence - uses cases should not refer to specific technology in their descriptions such as web, http, button, dropdown, etc. - this way the contents continue to be useful even if those decisions change.\nEnforces business flow - as described before the flow structure of use cases drive domain experts to think in a structured way and capture different situations helped also by engineers.\n\nMore details and better explanation can be found the links at the end in the References section.\nHowever the point of this article is how to organize the software architecture and code style to reflect the business flow description provided by use cases."
  },
  {
    "objectID": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#brief-introduction-to-use-cases",
    "href": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#brief-introduction-to-use-cases",
    "title": "Express business language in your code with use cases",
    "section": "",
    "text": "Use cases are a very important element in UML that addresses the functional aspect of a software. The use case diagram shows how the different system functionalities are associated to the different users in a system which are referred as actors.\n\nThe specific user kind is referred in UML as an actor. Note in the diagram above that a system can have several kinds of actors and an actor can be specialized from an existing one. For instance both Student and Teacher are specialized from School Member. This means they can also execute the same use cases from School Member which can serve to group common functionalities.\nAlso the objective of a use case is not just to describe a feature but to describe a business flow using a high level language that can be understood by the business expert on how a specific kind of user can achieve his goals.\nFor instance the “Enroll in Subject” use case can be described as follows:\n====================================================  \n**Project:** My School System  \n  \n**Subdomain:** Enrollment  \n  \n**Title:**  Enroll in Subject  \n  \n**Description:** Describes how a subject can be enrolled to a student.  \n  \n**Precondition:** student must be authenticated by the system.  \n  \n**Normal Flow:**  \n\n\n-   (n1) System lists all available subjects which were not enrolled or\n    completed by this student\n-   (n2) Student selects a subject\n-   (n3) System verifies if the subject is open for enrollment\n-   (n4) if subject is still open system enrolls student to it \\[a1\\]\n-   (n5) System sends a message to the student stating that the\n    enrollment was successful\n\n  \n**Alternative Flows:**  \n  \n&lt;u&gt;\\[a1\\] Subject is not open for enrollments:&lt;/u&gt; System sends a\nmessage to the user stating that the subject is not open for\nenrollment.  \n  \n**Integrity Constraints:**  \nStudent should not enroll in a subject he/she completed before.  \n  \n====================================================  \nUse cases popular in the 90s and begining of 2000s almost disappeared after that and recently there has been some interest in it perhaps because software engineers have identified a need to better understand the business flow in more details than what can be found in use cases.\nHowever use cases present many advantages such as:\n\nCommon language for engineers and domain experts - document can be the bridge between engineers and domain experts since it talks the language of the business in a structured way.\nTechnology independence - uses cases should not refer to specific technology in their descriptions such as web, http, button, dropdown, etc. - this way the contents continue to be useful even if those decisions change.\nEnforces business flow - as described before the flow structure of use cases drive domain experts to think in a structured way and capture different situations helped also by engineers.\n\nMore details and better explanation can be found the links at the end in the References section.\nHowever the point of this article is how to organize the software architecture and code style to reflect the business flow description provided by use cases."
  },
  {
    "objectID": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#organizing-code-around-use-cases",
    "href": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#organizing-code-around-use-cases",
    "title": "Express business language in your code with use cases",
    "section": "Organizing Code Around Use Cases",
    "text": "Organizing Code Around Use Cases\nThe following practices can be taken to clearly express use cases in your code:\n**\n** 1) Represent each use case as a class\nThe use case diagram above can be translated with the following class diagram:\n\nEach class represent a function in the system. Note that sometimes a use case may describe more than one scenario what can happen in CRUD functionalities such as Student Registration (which is not listed in our example diagram).\nNote that the name of the class should match the use case.\n2) Represent each use case flow step as a line of code\nCode expression inside use case classes should reflect as much as possible the business flow description so to make it simpler and easier to correlate the documentation and code.\nclass UseCaseSubjectEnrollment\n  def list_subjects(student)\n    Subject.list_available_for_student(student) # (n1)\n  end\n  def enroll(student, subject)\n    if subject.available_for_enrollment? # (n3) \n      student.enrolls(subject)           # (n4)\n      { \"type\" =&gt; \"success\", \"message\" =&gt; \"enrollment successful\" } # (n5)\n    else\n      { \"type\" =&gt; \"failure\", \"message\" =&gt; \"failed enrollment\" } # (a1)\n    end\n  end\nend\nNote that the use case method is broken in two parts since one of the steps describes a user interaction: “Student selects a subject”. The numbers in the use case and in the code above is optional and merely to make it clear for the reader to see the relation between them.\nBefore the user selection with list_subjects method and after the user selection with the enroll method. Due technological restrictions in web applications (at least in Ruby web applications) the user subject selection step is not represented in the use-case class but in the application layer presentation."
  },
  {
    "objectID": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#pros-and-cons-of-use-case-mapping-to-code",
    "href": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#pros-and-cons-of-use-case-mapping-to-code",
    "title": "Express business language in your code with use cases",
    "section": "Pros and Cons of Use Case Mapping to Code",
    "text": "Pros and Cons of Use Case Mapping to Code\nAfter some time using this approach for some years here are the positive and negative points:\nPros:\n\nA change in a use case document can be easily implemented by software engineers \nNewcomers quickly understand how and where to do code modifications with little or no help\nEngineers start work from the beginning with the business goal what reduces common misunderstanding in “what” the feature of functionality should be and its goals\nSometimes engineers can understand the business goal to the point of helping optimizing the business flow described by non-technical domain experts\n\nCons:\n\nIncludes one more step before engineers start developing software\nThere is a considerable effort to keep use cases updated \nDoesn’t pay off for highly dynamic and small websites where the business flow is simple and already known by engineers\n\nIn general it seems to me that the more complex a system is in term of business steps the better it is to start using use cases."
  },
  {
    "objectID": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#references",
    "href": "posts/2016-01-26-express-business-language-in-your-code-with-use-cases/index.html#references",
    "title": "Express business language in your code with use cases",
    "section": "References",
    "text": "References\n[1] Writing effective use cases - Alistair Cockburn - http://alistair.cockburn.us/get/2465\n[2] The art of writing use cases - Rebecca Wirfs-Brock - http://www.wirfs-brock.com/PDFs/Art_of_Writing_Use_Cases.pdf\n[3] Domain driven design quickly - Abel Avram - Floyd Marinescu - http://www.infoq.com/minibooks/domain-driven-design-quickly\n[4]    http://www.artima.com/articles/dci_vision.html - Trygve Reenskaug and James O. Coplien - The DCI Architecture: A New Vision of Object-Oriented Programming"
  },
  {
    "objectID": "posts/2010-02-22-unit-testing-linq-queries-in-moq/index.html",
    "href": "posts/2010-02-22-unit-testing-linq-queries-in-moq/index.html",
    "title": "Unit Testing Linq Queries in Moq",
    "section": "",
    "text": "After some google research and experimentation I found that it was not worth to mock methods that return IQueryable or IQueryable because in order to use it programmers have to make use of extension methods. And this kind of methods are not supported by Moq ( a minimalistic mock framework ). This is the DAO interface I want to test.\npublic interface IDAOFactory\n{\n  public abstract IQueryable Query();\n}\nThis is the moq unit test that fails, since I can´t use Linq directly.\n[Test]\npublic void LinqQueryTest()\n{ \n  // This moq configuration will trigger an exception\n  // Can´t make use of extension methods\n  daoFactoryMock.Setup(d =&gt; (from o in d.Query()\n    where o.Id &gt;= 0\n    select o.Id).ToList())\n    .Returns( new List() { 1, 2 } );\n}\nIt turns out that the solution is easily solved by using a collection as a data source.\n[Test]\npublic void LinqQueryTest()\n{\n  // Creates a IQueryable from a Collection\n  IList lstOrders = new List() { \n    orderMock1.Object, \n    orderMock2.Object, \n    orderMock3.Object };\n  IQueryable orderQuery = lstOrders.AsQueryable();\n\n  // Configures the Query to return IQueryable implementation\n  daoFactoryMock.Setup(d =&gt; d.Query()).Returns(orderQuery);\n\n  // Now the linq queries can be used naturally \n  IList lstResult = (from o in daoFactoryMock.Object.Query() \n                    where o.Id &gt;= 0 Select o).ToList();\n\n  // Checking output results\n  Assert.AreEqual(3, lstResult.Count);\n}\nIt is important to notice that the collection elements that should also be mock objects must contain all the necessary data in order to make the correct test."
  },
  {
    "objectID": "posts/2024-02-05-vector-space-for-words-and-document/index.html",
    "href": "posts/2024-02-05-vector-space-for-words-and-document/index.html",
    "title": "Vector Space for Documents",
    "section": "",
    "text": "Transforming document context into vectors provide several advantages such as:\n\ncalculate similarity between documents with vector distance\nfind similar groups of documents by applying a cluster algorithm\nget a visual representation of similar documents with dimensionality reduction\n\nThere are several designs to represent a document as a vector, one of the simplest is a word-count per document.\nAlso how to measure similarity between document vectors."
  },
  {
    "objectID": "posts/2024-02-05-vector-space-for-words-and-document/index.html#introduction",
    "href": "posts/2024-02-05-vector-space-for-words-and-document/index.html#introduction",
    "title": "Vector Space for Documents",
    "section": "",
    "text": "Transforming document context into vectors provide several advantages such as:\n\ncalculate similarity between documents with vector distance\nfind similar groups of documents by applying a cluster algorithm\nget a visual representation of similar documents with dimensionality reduction\n\nThere are several designs to represent a document as a vector, one of the simplest is a word-count per document.\nAlso how to measure similarity between document vectors."
  },
  {
    "objectID": "posts/2024-02-05-vector-space-for-words-and-document/index.html#transforming-a-document-into-a-vector",
    "href": "posts/2024-02-05-vector-space-for-words-and-document/index.html#transforming-a-document-into-a-vector",
    "title": "Vector Space for Documents",
    "section": "Transforming a Document into a Vector",
    "text": "Transforming a Document into a Vector\nIn this approach, each vector position represents a words and each value a frequency count (word-count).\nThis way the text below:\nI like to eat hamburguer.\nBuying peperoni hamburguer to eat.\nIs mapped as:\n\n\n\nI\nlike\nto\neat\nhamburguer\nbuying\npeperoni\n\n\n\n\n1\n1\n2\n2\n2\n1\n1"
  },
  {
    "objectID": "posts/2024-02-05-vector-space-for-words-and-document/index.html#similarity-among-documents",
    "href": "posts/2024-02-05-vector-space-for-words-and-document/index.html#similarity-among-documents",
    "title": "Vector Space for Documents",
    "section": "Similarity Among Documents",
    "text": "Similarity Among Documents\nUsing the idea describe above, several documents can be mapped as vectors and placed in a table such as:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndocument\nI\ndo\nplay\nweekend\nball\npeperoni\nsometimes\n…\n\n\n\n\nD1\n1\n2\n2\n0\n0\n2\n7\n…\n\n\nD2\n12\n0\n0\n2\n0\n0\n11\n…\n\n\nD3\n8\n12\n0\n0\n1\n1\n9\n…\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\nGiven that documents are represented as vector, the distance between 2 vectors can be calculated as:\n\nEuclidean distance \\(dist(D1, D2)=\\sqrt{ \\sum_{i=1}^{n} (D1 - D2)^2 }\\)\nCosine similarity \\(\\cos(\\theta)=\\frac{D1 \\cdot D2}{\\left \\| D1 \\right \\|  \\left \\| D2 \\right \\|}\\) \\(\\cos(\\theta)=\\frac{ \\sum_{i=1}^{n} D1_i D2_i }{ \\sqrt{ \\sum_{i=1}^{n} {D1_i}^2 } \\cdot \\sqrt{ \\sum_{i=1}^{n} {D2_i}^2 } }\\)\n\nPS: Prefer cosine similarity is preferred since it works well even with vectors with different magnitude.\nPS: Consider converting document vector to unitary vector before using with euclidean distance"
  },
  {
    "objectID": "posts/2024-02-05-vector-space-for-words-and-document/index.html#find-document-clusters",
    "href": "posts/2024-02-05-vector-space-for-words-and-document/index.html#find-document-clusters",
    "title": "Vector Space for Documents",
    "section": "Find Document Clusters",
    "text": "Find Document Clusters\n\nK-Means with Euclidean Distance\nEuclidean distance provides a distance function between 2 document-vectors D1 and D2 by considering each dimension distance separately.\nBesides an average vector can be calculated by averaging a dataset of document vectors in a table \\(DT\\).\n\\(DT=\\frac{ \\sum_{i=1}^{n} DT_i }{ n }\\)\nGiven the documents:\n\n\n\ndocument\nI\ndo\nplay\nweekend\nball\npeperoni\nsometimes\n\n\n\n\nD1\n1\n2\n2\n0\n0\n2\n7\n\n\nD2\n12\n0\n0\n2\n0\n0\n11\n\n\nD3\n8\n12\n0\n0\n1\n1\n9\n\n\n\nThe sum of those documents are:\n\n\n\n\nI\ndo\nplay\nweekend\nball\npeperoni\nsometimes\n\n\n\n\nsum\n21\n14\n2\n2\n1\n3\n27\n\n\n\nwith n = 3 (number of documents) then average vector is:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI\ndo\nplay\nweekend\nball\npeperoni\nsometimes\n\n\n\n\naverage\n7\n4.667\n0.667\n0.667\n0.333\n1\n9\n\n\n\nGiven a enclidean distance and average functions above, then a cluster mechanism can be built on top of a cluster algorithm such as K-means whose standard steps are described as:\n\n\\(K\\) initial vectors are randomly generated inside data range as centroids\nEach document-vector is associated to the closest centroid using the distance function (K clusters)\nInside each cluster \\(K_i\\), a new centroid is calculated with average vector function\nRepeat steps 2 and 3 until the distance of new centroid’s locations from original is less than a threshold"
  },
  {
    "objectID": "posts/2024-02-05-vector-space-for-words-and-document/index.html#visual-representation-with-dimensionality-reduction",
    "href": "posts/2024-02-05-vector-space-for-words-and-document/index.html#visual-representation-with-dimensionality-reduction",
    "title": "Vector Space for Documents",
    "section": "Visual Representation with Dimensionality Reduction",
    "text": "Visual Representation with Dimensionality Reduction\nVisualising documents in 2 dimensions can provide a graphical and intuitive way to communicate how or perhaps why groups of documents are created.\nFirst each document vector need to be mapped to a 2 dimension vector so it can be visualised with PCA (principal component analysis).\nDetails on PCA can be found here.\nWith the 2D document vectors, one can come up with a visualisation such as scatterplot to present to an audience or gain more insigths on the data:"
  },
  {
    "objectID": "posts/2024-02-05-vector-space-for-words-and-document/index.html#conclusion",
    "href": "posts/2024-02-05-vector-space-for-words-and-document/index.html#conclusion",
    "title": "Vector Space for Documents",
    "section": "Conclusion",
    "text": "Conclusion\nLearning how to convert document to vector can help perform analysis more quickly. Some applications are cited above however there are more, for instance, document-vectors that belong to the same category such as finance, movies, tech, etc can be summed up together to describe a vector information of that group and perhaps help classify another document to the nearest category using a distance function.\nThe new document to be classified just needs to be converted to a vector and then this vector needs to be compared by distance to the document-category vectors.\nAnother application is to detect plagiarism, by measuring the distance between a given input document to a dataset of known documents."
  },
  {
    "objectID": "posts/2008-07-18-5-things-you-should-remember-about-nhibernate/index.html",
    "href": "posts/2008-07-18-5-things-you-should-remember-about-nhibernate/index.html",
    "title": "5 Things You Should Remember about NHibernate",
    "section": "",
    "text": "NHibernate is probably the most used ORM (object-relational mapping tool) for .NET applications and it is based in Hibernate the most used ORM in Java for years.\nThe learning curve to start working with NHibernate can be reduced if you remember the take the following steps:\n\nThe domain class should have at least one public or protected parameterless constructor\nThe domain classes’ public properties and methods must declared with the virtual reserved word\nFor XML mappings, remember to rename your mapping files ending with *.hbm.xml not only *.xml\nAlso for XML mappings, remember to set the property of each file to embedded resource instead of content\nAvoid using composite-id’s classes as much as you can since they don’t work very well when used in cascade collections and they make development more difficult"
  },
  {
    "objectID": "posts/2008-07-18-unit-tests-rule-software-development/index.html",
    "href": "posts/2008-07-18-unit-tests-rule-software-development/index.html",
    "title": "Unit Tests Rule Software Development",
    "section": "",
    "text": "Even after a relatively long time using object oriented systems we still couldn’t deal well with a growing problem. The lack of automated tests.\nThe absence of unit tests reduce the programmers confidence about the system and makes it very difficult if not impossible to modify the source-code. Since each modification can cause a lot of other bugs and undesired side-effects in other parts of the system or in other systems, the system can not evolve with the changing business rules and the changing technological knowledge.\nWell that was true some months ago, now we are building a lot of unit tests for the systems already in production. Ironically due to some good architectural choices such as persistence isolation and POCO objects, it was not difficult to start testing with the Stub technique. It was all there, we just started creating test cases.\nIn reality, although not the ideal way, a set of use-case tests are being implemented in order to assure the right execution of what was working before. So the service layer is tested not the business objects at this time.\nNow we are looking for automated ways to create mode real test cases in other to produce all the tests we need as fast as we can. Perhaps a testing framework will be necessary."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Articles",
    "section": "",
    "text": "Vector Space for Documents\n\n\n\n\n\n\nmachine-learning\n\n\n\nWhy and how to use vector to extract information from documents\n\n\n\n\n\nFeb 5, 2024\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nText Classification with Logistic Regression\n\n\n\n\n\n\nmachine-learning\n\n\n\nText classification with logistic regression\n\n\n\n\n\nJul 28, 2023\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nText Classification with Naive Baye’s\n\n\n\n\n\n\nmachine-learning\n\n\n\nImproved techniques to implement Naive Bayes for text classification such as Laplacian Smoothing and Log Likelihood\n\n\n\n\n\nMay 7, 2023\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nApr 7, 2023\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nExpress business language in your code with use cases\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJan 26, 2016\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nFrom static-language style API to Ruby style API\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJul 26, 2015\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Unit Test in C#.NET\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJul 16, 2015\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nCreate an Agnostic Vendor Infrastructure in Ruby\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJan 26, 2015\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nRails: New Framework - Old Design Problems\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nDec 18, 2013\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nRORM - Ruby Domain Objects with Persistence\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nDec 6, 2012\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nSeparated Interface Design Pattern\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nNov 12, 2012\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nJavaScript: Object Oriented Programming\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nAug 28, 2011\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nPublishing ClickOnce winforms applications with command-line MSBuild\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nFeb 27, 2011\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\niPhone Development: to Objective-C or not to Objective-C ?\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nFeb 27, 2011\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nTools and Utilities for the .NET Developer\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJun 3, 2010\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Fluent Builder Pattern to Configure Test Objects\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nMay 9, 2010\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nTest-Driven-Development Best Practices\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nMay 8, 2010\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nName Convention for Object Oriented Apps\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nFeb 24, 2010\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nUnit Testing Linq Queries in Moq\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nFeb 22, 2010\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nModel View Controller with Events in .NET\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nDec 26, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme Programming Impressions\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nSep 27, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nDynamicProxy: An Elegant Solution for Session/Transaction/Exception Management in NHibernate (or any other ORM)\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nAug 27, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nAvoid ‘Tall’ DAO Factories\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nAug 21, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nAgile Modeling in Software Projects\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJun 13, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nHow the repository pattern works ?\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJun 10, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\n.NET: Using Generics to avoid repetition in Domain Classes\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nMar 14, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nUsing .NET Nullable Types with NHibernate 1.2\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nMar 12, 2009\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nExtremely Short Introduction for Ruby on Rails\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nDec 26, 2008\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Software Documentation from Unit Tests\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nNov 23, 2008\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Software Development Process with Open-Source Tools for .NET\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nAug 19, 2008\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nScrum as a criteria for Venture Capital Groups\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJul 24, 2008\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\n5 Things You Should Remember about NHibernate\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJul 18, 2008\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nUnit Tests Rule Software Development\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJul 18, 2008\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nRich Domain Objects\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nMar 19, 2008\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nBest Practice to Handle Exceptions\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nDec 20, 2007\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nChoosing the Right Primary Keys\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nDec 3, 2007\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nLess is More - Dynamically typed languages\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nOct 17, 2007\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nPackages: A Tool to Organize Classes\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nAug 30, 2007\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nWhy developers do not like to model the Real World ?\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nJul 3, 2007\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Big Enterprise System with NHibernate\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nMay 9, 2007\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nDelphi for OO Programmers\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nNov 9, 2006\n\n\nHumberto C Marchezi\n\n\n\n\n\n\n\n\n\n\n\n\nOO Paradigm Popularity\n\n\n\n\n\n\nsoftware-engineering\n\n\n\n\n\n\n\n\n\nOct 28, 2006\n\n\nHumberto C Marchezi\n\n\n\n\n\n\nNo matching items"
  }
]